{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quick Drawing is a kaggle challenge for classifying the sketch pictures. The total number of category is 340 and \n",
    "there are 50M pictures in the dataset. Each catogory has 25,000 pictures. The difficulty is the drawing might be \n",
    "incomplete or the drawing does not match the label. We are trying to develop a CNN to solve the issue.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the challenge, there are 4 kinds of dataset. \n",
    "\n",
    "    - Raw data (.ndjson)\n",
    "    - Simplified drawings (.ndjson)\n",
    "    - Binary data (.bin)\n",
    "    - Bitmap data (.npy)\n",
    "Raw data and Simplified drawings are provided in a vector information of strokes. Bitmap data is rendered into \n",
    "28 * 28 grayscale bitmap in the numpy format.  \n",
    "\n",
    "Maybe we could consider the raw data to improve the performance since it inlcudes the sequence information.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import time\n",
    "import torch\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import sampler\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as T\n",
    "import numpy as np\n",
    "from torch.utils import data\n",
    "import QDdata as QD\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from torch.utils.data import DataLoader\n",
    "import resnet as RN\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device: cuda\n"
     ]
    }
   ],
   "source": [
    "USE_GPU = True\n",
    "\n",
    "dtype = torch.float32 # we will be using float throughout this tutorial\n",
    "\n",
    "if USE_GPU and torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "# Constant to control how frequently we print train loss\n",
    "print_every = 300\n",
    "\n",
    "print('using device:', device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans = transforms.Compose([transforms.RandomHorizontalFlip(0.5), transforms.ToTensor()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resnet50 96X96"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following codes comes from cs231N.\n",
    "from average_precision import mapk\n",
    "def mean_ap_torch(y_val,y_pred_score,k):\n",
    "    y_pred = [torch.sort(c,descending=True)[::-1][1][:k] for c in y_pred_score]\n",
    "    return mapk(y_val,y_pred,k)\n",
    "\n",
    "def mean_ap_3(y_val,y_pred_score,k):\n",
    "    y_pred = [np.argsort(c)[::-1][:k] for c in y_pred_score]\n",
    "    return mapk(y_val,y_pred,k)\n",
    "\n",
    "def check_accuracy(loader, model):\n",
    "    \n",
    "    model.eval()  # set model to evaluation mode\n",
    "    \n",
    "    meanAP = []\n",
    "    meanAP3 = []\n",
    "    with torch.no_grad():\n",
    "        for i ,(x, y) in enumerate(loader):\n",
    "            x = x.to(device=device, dtype=dtype)  # move to device, e.g. GPU\n",
    "            y = y.to(device=device, dtype=torch.long)\n",
    "            y_pred = model(x)\n",
    "            y_val = y.reshape(-1,1)\n",
    "            y_pred = y_pred.data.cpu().numpy()\n",
    "            \n",
    "            mAP = 100 * mean_ap_3(y_val,y_pred,1)\n",
    "            mAP3 = 100 * mean_ap_3(y_val,y_pred,3)\n",
    "            meanAP.append(mAP)\n",
    "            meanAP3.append(mAP3)\n",
    "            if i > 300:\n",
    "                break\n",
    "        \n",
    "        m1 = np.mean(meanAP)\n",
    "        m3 = np.mean(meanAP3)\n",
    "        \n",
    "\n",
    "        if (m3 > QDtrain[\"mAP3\"] + 1) and (m3 > 20):\n",
    "            if os.path.exists(QDtrain[\"file\"]):\n",
    "                os.remove(QDtrain[\"file\"])\n",
    "            QDtrain[\"file\"] = str(\"model\" + QDtrain[\"prefix\"] + str(m3))\n",
    "            torch.save(model.state_dict(),QDtrain[\"file\"])\n",
    "            QDtrain[\"mAP3\"] = m3\n",
    "            QDtrain[\"mAP\"] = m1\n",
    "        print('Got correct (%.2f,%.2f)' % (m1,m3 ))\n",
    "        \n",
    "        \n",
    "def train(model, optimizer, epochs=1):\n",
    "    \"\"\"\n",
    "    Train a model on quickdrawing.\n",
    "    \n",
    "    Inputs:\n",
    "    - model: A PyTorch Module giving the model to train.\n",
    "    - optimizer: An Optimizer object we will use to train the model\n",
    "    - epochs: A Python integer giving the number of epochs to train for\n",
    "    \n",
    "    Returns: Nothing, but prints model accuracies during training.\n",
    "    \"\"\"\n",
    "    model = model.to(device=device)  # move the model parameters to CPU/GPU\n",
    "    loader_val = QD.QDloadData(no=10)\n",
    "    loader_val = DataLoader(dataset=loader_val, batch_size=128,shuffle=True)\n",
    "    \n",
    "    for e in range(epochs):\n",
    "        \n",
    "        for i in range(4):\n",
    "            train_dataset = QD.QDloadData(no=i,transforms = trans)          \n",
    "            train_loader = DataLoader(dataset=train_dataset, batch_size=128,shuffle=True)\n",
    "            #loader_val = train_loader\n",
    "            t1 = time.time()\n",
    "            for t, (x, y) in enumerate(train_loader):\n",
    "                model.train()  # put model to training mode\n",
    "                x = x.to(device=device, dtype=dtype)  # move to device, e.g. GPU\n",
    "                y = y.to(device=device, dtype=torch.long)\n",
    "\n",
    "                scores = model(x)\n",
    "                loss = F.cross_entropy(scores, y)\n",
    "\n",
    "                # Zero out all of the gradients for the variables which the optimizer\n",
    "                # will update.\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # This is the backwards pass: compute the gradient of the loss with\n",
    "                # respect to each  parameter of the model.\n",
    "                loss.backward()\n",
    "\n",
    "                # Actually update the parameters of the model using the gradients\n",
    "                # computed by the backwards pass.\n",
    "                optimizer.step()\n",
    "                t2 = time.time()\n",
    "\n",
    "                #print(e,t,t2-t1)\n",
    "                if t % print_every == 0:\n",
    "                    print('Epoch %d,Iteration %d, loss = %.4f time %.4f' % (e,t, loss.item(),t2-t1))\n",
    "                    check_accuracy(loader_val, model)\n",
    "                    t1 = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RN.resnet50(num_classes=40)\n",
    "learning_rate = 1e-3\n",
    "optimizer = optim.Adam(model.parameters(),weight_decay = 1e-5,lr=learning_rate)\n",
    "QDtrain = {\"mAP\":0,\"mAP3\":0,\"file\":\"\",\"prefix\":\"resnet50\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data10.npy label10.npy\n",
      "Total number of items: 120000\n",
      "data0.npy label0.npy\n",
      "Total number of items: 120000\n",
      "Epoch 0,Iteration 0, loss = 3.9519 time 0.1754\n",
      "Got correct (2.42,4.43)\n",
      "Epoch 0,Iteration 300, loss = 1.4472 time 47.7834\n",
      "Got correct (53.18,63.93)\n",
      "Epoch 0,Iteration 600, loss = 1.1170 time 46.9895\n"
     ]
    }
   ],
   "source": [
    "train(model, optimizer, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. batch size = 64. count =  340 * 10240.\n",
    "   Iteration 29400, loss = 0.5610\n",
    "   Got 64 correct (80.22,85.62)\n",
    "2. batch size =128 count = 340 *10240 * 2\n",
    "    Iteration 37800, loss = 0.9535\n",
    "    Got 128 correct (77.65,83.64)\n",
    "3. batch size =128 count = 340 *10240 * 2 \n",
    "    train on 28 * 28 drawing transfered from stroke\n",
    "    Iteration 45900, loss = 0.9149\n",
    "    Got correct (57.55,65.98)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline 28X28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset28 = QD.QDDetection(count = 40 * 3000*9 ,images_category = 3000*9,transforms = trans)\n",
    "loader_dataset28 = QD.QDDetection(count = 40 * 512,start = 3000*9, images_category = 3000)\n",
    "train_loader28 = DataLoader(dataset=train_dataset28, batch_size=128, num_workers=2, shuffle=True)\n",
    "loader_val28 = DataLoader(dataset=loader_dataset28, batch_size=128,shuffle=True)\n",
    "\n",
    "def train28(model, optimizer, epochs=1):\n",
    "    model = model.to(device=device)  # move the model parameters to CPU/GPU\n",
    "    for e in range(epochs):\n",
    "        t1 = time.time()\n",
    "        for t, (x, y) in enumerate(train_loader28):\n",
    "            model.train()  # put model to training mode\n",
    "            x = x.to(device=device, dtype=dtype)  # move to device, e.g. GPU\n",
    "            y = y.to(device=device, dtype=torch.long)\n",
    "\n",
    "            scores = model(x)\n",
    "            loss = F.cross_entropy(scores, y)\n",
    "\n",
    "            # Zero out all of the gradients for the variables which the optimizer\n",
    "            # will update.\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # This is the backwards pass: compute the gradient of the loss with\n",
    "            # respect to each  parameter of the model.\n",
    "            loss.backward()\n",
    "\n",
    "            # Actually update the parameters of the model using the gradients\n",
    "            # computed by the backwards pass.\n",
    "            optimizer.step()\n",
    "\n",
    "            t2 = time.time()\n",
    "            if t % print_every == 0:\n",
    "                print('Iteration %d, loss = %.4f time:%.4f' % (t, loss.item(),t2 - t1))\n",
    "                check_accuracy(loader_val28, model)\n",
    "                t1 = time.time()\n",
    "\n",
    "\n",
    "learning_rate28 = 1e-3\n",
    "\n",
    "def flatten(x):\n",
    "    N = x.shape[0] # read in N, C, H, W\n",
    "    return x.view(N, -1)  # \"flatten\" the C * H * W values into a single vector per image\n",
    "\n",
    "class Flatten(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return flatten(x)\n",
    "\n",
    "    \n",
    "model28 = nn.Sequential(\n",
    "    nn.Conv2d(1,64,3,padding=1),\n",
    "    nn.BatchNorm2d(64),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(64,64,3,padding=1),\n",
    "    nn.BatchNorm2d(64),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(64,128,3,padding=1),\n",
    "    nn.BatchNorm2d(128),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(128,256,3,padding=1),\n",
    "    nn.BatchNorm2d(256),\n",
    "    nn.ReLU(),\n",
    "    nn.AvgPool2d(4),\n",
    "    Flatten(),\n",
    "    nn.Linear(12544, 40),\n",
    ")\n",
    "\n",
    "# you can use Nesterov momentum in optim.SGD\n",
    "optimizer28 = optim.Adam(model28.parameters(), lr=learning_rate28)\n",
    "\n",
    "QDtrain = {\"mAP\":0,\"mAP3\":0,\"file\":\"\",\"prefix\":\"base28\"}\n",
    "train28(model28, optimizer28, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline model (96X96)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_learning_rate = 1e-4\n",
    "\n",
    "def flatten(x):\n",
    "    N = x.shape[0] # read in N, C, H, W\n",
    "    return x.view(N, -1)  # \"flatten\" the C * H * W values into a single vector per image\n",
    "\n",
    "class Flatten(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return flatten(x)\n",
    "\n",
    "    \n",
    "base_model = nn.Sequential(\n",
    "    nn.Conv2d(1,64,3,stride = 1,padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(64,128,3,stride = 2,padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(128,128,3,stride = 1,padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(3,stride = 2,padding = 1),\n",
    "    nn.Conv2d(128,256,3,stride = 2,padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(256,256,3,stride = 1,padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(3,stride = 2,padding = 1),\n",
    "    Flatten(),\n",
    "    nn.Linear(9216,4096),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(4096,40)\n",
    ")\n",
    "\n",
    "\n",
    "base_optimizer = optim.Adam(base_model.parameters(),lr=base_learning_rate)\n",
    "QDtrain = {\"mAP\":0,\"mAP3\":0,\"file\":\"\",\"prefix\":\"base96\"}\n",
    "train(base_model, base_optimizer, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sketch-A-Net model(256 X 256)\n",
    "* The following code is based on Sketch-A-Net that Beats Humans."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SN_learning_rate = 1e-3\n",
    "\n",
    "def flatten(x):\n",
    "    N = x.shape[0] # read in N, C, H, W\n",
    "    return x.view(N, -1)  # \"flatten\" the C * H * W values into a single vector per image\n",
    "\n",
    "class Flatten(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return flatten(x)\n",
    "\n",
    "    \n",
    "SN_model = nn.Sequential(\n",
    "    nn.Conv2d(1,64,15,stride = 3,padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(3,stride = 2,padding = 0),\n",
    "    \n",
    "    nn.Conv2d(35,128,5,stride = 1,padding=0),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(3,stride = 2,padding = 0),\n",
    "    \n",
    "    nn.Conv2d(15,256,3,stride = 1,padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(15,256,3,stride = 1,padding=1),\n",
    "    nn.ReLU(),    \n",
    "    nn.Conv2d(15,256,3,stride = 1,padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(3,stride = 2,padding = 0),\n",
    "\n",
    "    Flatten(),\n",
    "    nn.Linear(256*7*7,512),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(),\n",
    "    \n",
    "    nn.Linear(512,512),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(),\n",
    "    \n",
    "    nn.Linear(512,40)\n",
    ")\n",
    "\n",
    "\n",
    "SN_optimizer = optim.Adam(SN_model.parameters(),weight_decay = 1e-5,lr=SN_learning_rate)\n",
    "QDtrain = {\"mAP\":0,\"mAP3\":0,\"file\":\"\",\"prefix\":\"sketchanet\"}\n",
    "train(SN_model, SN_optimizer, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run test samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def evaluate_test(test_data, model,y):\n",
    "    model.eval()  # set model to evaluation mode\n",
    "    with torch.no_grad():\n",
    "        meanAP = []\n",
    "        meanAP3 = []\n",
    "        for i ,x in enumerate(test_data):\n",
    "            x = x.to(device=device, dtype=dtype)  # move to device, e.g. GPU\n",
    "            #y = y_label.to(device=device, dtype=torch.long)\n",
    "            y_pred = model(x)\n",
    "            y_val = y.reshape(-1,1)\n",
    "            y_pred = y_pred.data.cpu().numpy()\n",
    "            \n",
    "            mAP = 100 * mean_ap_3(y_val,y_pred,1)\n",
    "            mAP3 = 100 * mean_ap_3(y_val,y_pred,3)\n",
    "            meanAP.append(mAP)\n",
    "            meanAP3.append(mAP3)\n",
    "        \n",
    "        m1 = np.mean(meanAP)\n",
    "        m3 = np.mean(meanAP3)\n",
    "        return (m1,m3)\n",
    "\n",
    "model = base_model.to(device=device)\n",
    "checkpoint = torch.load(\"model_parameter99.3972598.87986\")\n",
    "model.load_state_dict(checkpoint)\n",
    "\n",
    "class_name = QD.QDloadtest(name = \"./data1.npy\")\n",
    "class_name = class_name.class_names\n",
    "\n",
    "class_accuracy = []\n",
    "\n",
    "for i,name in enumerate(tqdm(class_name)):\n",
    "    test_data = QD.QDloadtest(name=os.path.join(\"../cs230/pic96\",name+\".npz\"),image_size=(96,96))\n",
    "    test_loader = DataLoader(dataset=test_data, batch_size=128, num_workers=2, shuffle=False)\n",
    "    y = np.ones(len(test_data))*i\n",
    "    m1,m3 = evaluate_test(test_loader,model,y)\n",
    "    print(name,m1,m3)\n",
    "    class_accuracy.append((name,str(m1),str(m3)))\n",
    "    \n",
    "with open('class_accuracy.csv',\"w+\") as fp:\n",
    "    writer = csv.writer(fp, delimiter=',')\n",
    "    writer.writerow([\"class\", \"meanAP1\", \"meanAP3\"])  # write header\n",
    "    writer.writerows(class_accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) 96*96, resnet50, epoch 10, GSD. 75.2%\n",
    "2) 96*96, resnet50, epoch 10, GSD  79.9% model_parametertensor(91.6667)\n",
    "3) 96*96, resnet50, epoch 10, Adam model_resnet_92.317_90\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* convert simplified test dataset to pixel drawsing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the accuracy based on the class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create test_simplified.\n",
    "load compressed(96*96) 1.968482494354248\n",
    "load non compressed(96*96)  0.31299567222595215\n",
    "load non compressed(28*28) 0.04715704917907715\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10,11):\n",
    "    data = QD.QDcreateData()\n",
    "    data.create(start=i*3000,dir_name=\"../cs230/pic96\")\n",
    "    del data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
