{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quick Drawing is a kaggle challenge for classifying the sketch pictures. The total number of category is 340 and \n",
    "there are 50M pictures in the dataset. Each catogory has 25,000 pictures. The difficulty is the drawing might be \n",
    "incomplete or the drawing does not match the label. We are trying to develop a CNN to solve the issue.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the challenge, there are 4 kinds of dataset. \n",
    "\n",
    "    - Raw data (.ndjson)\n",
    "    - Simplified drawings (.ndjson)\n",
    "    - Binary data (.bin)\n",
    "    - Bitmap data (.npy)\n",
    "Raw data and Simplified drawings are provided in a vector information of strokes. Bitmap data is rendered into \n",
    "28 * 28 grayscale bitmap in the numpy format.  \n",
    "\n",
    "Maybe we could consider the raw data to improve the performance since it inlcudes the sequence information.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import time\n",
    "import torch\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import sampler\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as T\n",
    "import numpy as np\n",
    "from torch.utils import data\n",
    "import QDdata as QD\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from torch.utils.data import DataLoader\n",
    "import resnet as RN\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device: cuda\n"
     ]
    }
   ],
   "source": [
    "USE_GPU = True\n",
    "\n",
    "dtype = torch.float32 # we will be using float throughout this tutorial\n",
    "\n",
    "if USE_GPU and torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "# Constant to control how frequently we print train loss\n",
    "print_every = 300\n",
    "\n",
    "print('using device:', device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans = transforms.Compose([transforms.RandomHorizontalFlip(0.5), transforms.ToTensor()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline 28X28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 2/40 [00:00<00:02, 14.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total class number:40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:02<00:00, 14.22it/s]\n",
      "  8%|▊         | 3/40 [00:00<00:01, 19.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of items: 1080000 1080000\n",
      "Total class number:40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:01<00:00, 24.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of items: 20480 20480\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, loss = 3.7049 time:0.1277\n",
      "Got correct (2.50,4.64)\n",
      "Iteration 300, loss = 2.0869 time:9.1140\n",
      "Got correct (41.77,52.32)\n",
      "Iteration 600, loss = 1.9954 time:9.0852\n",
      "Got correct (48.26,58.28)\n",
      "Iteration 900, loss = 1.8500 time:9.0782\n",
      "Got correct (49.98,60.35)\n",
      "Iteration 1200, loss = 1.7586 time:9.0969\n",
      "Got correct (52.89,62.77)\n",
      "Iteration 1500, loss = 1.6334 time:9.0801\n",
      "Got correct (53.84,63.72)\n",
      "Iteration 1800, loss = 1.5295 time:9.0829\n",
      "Got correct (54.31,64.10)\n",
      "Iteration 2100, loss = 1.8036 time:9.0794\n",
      "Got correct (56.26,66.05)\n",
      "Iteration 2400, loss = 1.5614 time:9.1045\n",
      "Got correct (54.32,64.24)\n",
      "Iteration 2700, loss = 1.5502 time:9.0863\n",
      "Got correct (55.03,64.93)\n",
      "Iteration 3000, loss = 1.3300 time:9.0854\n",
      "Got correct (58.02,67.37)\n",
      "Iteration 3300, loss = 1.5667 time:9.0991\n",
      "Got correct (57.50,67.26)\n",
      "Iteration 3600, loss = 1.3900 time:9.0788\n",
      "Got correct (57.70,67.32)\n",
      "Iteration 3900, loss = 1.5099 time:9.0781\n",
      "Got correct (58.89,68.35)\n",
      "Iteration 4200, loss = 1.3182 time:9.0794\n",
      "Got correct (59.07,68.40)\n",
      "Iteration 4500, loss = 1.3723 time:9.0974\n",
      "Got correct (58.81,68.45)\n",
      "Iteration 4800, loss = 1.4622 time:9.0850\n",
      "Got correct (59.68,69.16)\n",
      "Iteration 5100, loss = 1.4721 time:9.0665\n",
      "Got correct (59.71,69.08)\n",
      "Iteration 5400, loss = 1.5102 time:9.0711\n",
      "Got correct (59.26,68.92)\n",
      "Iteration 5700, loss = 1.2931 time:9.0920\n",
      "Got correct (58.19,68.15)\n",
      "Iteration 6000, loss = 1.1783 time:9.0639\n",
      "Got correct (61.33,70.64)\n",
      "Iteration 6300, loss = 1.3857 time:9.0776\n",
      "Got correct (57.57,67.23)\n",
      "Iteration 6600, loss = 1.3733 time:9.0794\n",
      "Got correct (60.87,70.34)\n",
      "Iteration 6900, loss = 1.4102 time:9.0905\n",
      "Got correct (52.92,62.89)\n",
      "Iteration 7200, loss = 1.3849 time:9.0874\n",
      "Got correct (59.85,69.11)\n",
      "Iteration 7500, loss = 1.3335 time:9.0648\n",
      "Got correct (61.44,70.66)\n",
      "Iteration 7800, loss = 1.2936 time:9.0790\n",
      "Got correct (61.61,70.72)\n",
      "Iteration 8100, loss = 1.4175 time:9.0864\n",
      "Got correct (61.89,71.02)\n",
      "Iteration 8400, loss = 1.1278 time:9.0778\n",
      "Got correct (61.67,71.05)\n",
      "Iteration 0, loss = 1.1173 time:0.1768\n",
      "Got correct (62.07,71.38)\n",
      "Iteration 300, loss = 1.6366 time:9.0667\n",
      "Got correct (62.34,71.51)\n",
      "Iteration 600, loss = 1.3173 time:9.0966\n",
      "Got correct (62.08,71.32)\n",
      "Iteration 900, loss = 1.4799 time:9.0686\n",
      "Got correct (62.23,71.30)\n",
      "Iteration 1200, loss = 1.3067 time:9.0833\n",
      "Got correct (62.24,71.36)\n",
      "Iteration 1500, loss = 1.1593 time:9.0728\n",
      "Got correct (62.90,71.93)\n",
      "Iteration 1800, loss = 1.1473 time:9.0950\n",
      "Got correct (62.56,71.81)\n",
      "Iteration 2100, loss = 1.2813 time:9.0722\n",
      "Got correct (63.00,72.05)\n",
      "Iteration 2400, loss = 1.1843 time:9.0758\n",
      "Got correct (63.02,72.11)\n",
      "Iteration 2700, loss = 1.1231 time:9.0699\n",
      "Got correct (62.80,71.91)\n",
      "Iteration 3000, loss = 1.1660 time:9.0883\n",
      "Got correct (62.27,71.46)\n",
      "Iteration 3300, loss = 1.1152 time:9.0685\n",
      "Got correct (61.37,70.46)\n",
      "Iteration 3600, loss = 1.2458 time:9.1014\n",
      "Got correct (63.60,72.46)\n",
      "Iteration 3900, loss = 1.1719 time:9.0663\n",
      "Got correct (62.52,71.78)\n",
      "Iteration 4200, loss = 1.1161 time:9.0943\n",
      "Got correct (62.76,72.01)\n",
      "Iteration 4500, loss = 1.1611 time:9.0720\n",
      "Got correct (61.28,70.55)\n",
      "Iteration 4800, loss = 1.1414 time:9.0649\n",
      "Got correct (63.70,72.83)\n",
      "Iteration 5100, loss = 1.2721 time:9.0801\n",
      "Got correct (62.34,71.46)\n",
      "Iteration 5400, loss = 1.0489 time:9.0728\n",
      "Got correct (63.48,72.44)\n",
      "Iteration 5700, loss = 1.3779 time:9.0687\n",
      "Got correct (63.04,72.01)\n",
      "Iteration 6000, loss = 1.1465 time:9.0549\n",
      "Got correct (60.43,70.00)\n",
      "Iteration 6300, loss = 1.0408 time:9.0848\n",
      "Got correct (63.88,72.78)\n",
      "Iteration 6600, loss = 1.1833 time:9.0593\n",
      "Got correct (63.08,71.96)\n",
      "Iteration 6900, loss = 1.3092 time:9.0678\n",
      "Got correct (63.74,72.69)\n",
      "Iteration 7200, loss = 1.1034 time:9.0663\n",
      "Got correct (62.11,71.36)\n",
      "Iteration 7500, loss = 1.0405 time:9.0688\n",
      "Got correct (64.03,73.01)\n",
      "Iteration 7800, loss = 1.0537 time:9.0645\n",
      "Got correct (64.14,73.01)\n",
      "Iteration 8100, loss = 1.1095 time:9.0664\n",
      "Got correct (64.38,73.28)\n",
      "Iteration 8400, loss = 1.2090 time:9.0626\n",
      "Got correct (63.71,72.74)\n",
      "Iteration 0, loss = 1.0593 time:0.1834\n",
      "Got correct (64.06,72.85)\n",
      "Iteration 300, loss = 1.0796 time:9.0550\n",
      "Got correct (63.78,72.75)\n",
      "Iteration 600, loss = 1.1382 time:9.0532\n",
      "Got correct (61.69,70.99)\n",
      "Iteration 900, loss = 1.0537 time:9.0649\n",
      "Got correct (63.97,73.04)\n",
      "Iteration 1200, loss = 1.4013 time:9.0808\n",
      "Got correct (63.96,73.00)\n",
      "Iteration 1500, loss = 1.3774 time:9.0607\n",
      "Got correct (63.63,72.49)\n",
      "Iteration 1800, loss = 1.3254 time:9.0716\n",
      "Got correct (64.01,72.95)\n",
      "Iteration 2100, loss = 1.5390 time:9.0573\n",
      "Got correct (64.54,73.38)\n",
      "Iteration 2400, loss = 1.1489 time:9.0783\n",
      "Got correct (63.65,72.72)\n",
      "Iteration 2700, loss = 1.0277 time:9.0496\n",
      "Got correct (63.99,73.18)\n",
      "Iteration 3000, loss = 1.1810 time:9.0607\n",
      "Got correct (64.86,73.59)\n",
      "Iteration 3300, loss = 1.2554 time:9.0658\n",
      "Got correct (55.97,65.61)\n",
      "Iteration 3600, loss = 1.0579 time:9.0698\n",
      "Got correct (59.35,68.99)\n",
      "Iteration 3900, loss = 1.0441 time:9.0583\n",
      "Got correct (64.34,73.25)\n",
      "Iteration 4200, loss = 1.1021 time:9.0578\n",
      "Got correct (64.26,73.18)\n",
      "Iteration 4500, loss = 1.0869 time:9.0716\n",
      "Got correct (64.09,73.16)\n",
      "Iteration 4800, loss = 1.1893 time:9.0634\n",
      "Got correct (64.39,73.40)\n",
      "Iteration 5100, loss = 1.0987 time:9.0762\n",
      "Got correct (64.79,73.56)\n",
      "Iteration 5400, loss = 1.1439 time:9.0495\n",
      "Got correct (64.47,73.45)\n",
      "Iteration 5700, loss = 1.4363 time:9.0671\n",
      "Got correct (64.33,73.33)\n",
      "Iteration 6000, loss = 1.2846 time:9.0774\n",
      "Got correct (64.52,73.45)\n",
      "Iteration 6300, loss = 1.1678 time:9.0534\n",
      "Got correct (64.50,73.46)\n",
      "Iteration 6600, loss = 0.9947 time:9.0532\n",
      "Got correct (63.20,72.30)\n",
      "Iteration 6900, loss = 1.3627 time:9.0639\n",
      "Got correct (65.18,73.89)\n",
      "Iteration 7200, loss = 1.3202 time:9.0680\n",
      "Got correct (64.88,73.75)\n",
      "Iteration 7500, loss = 1.1362 time:9.0744\n",
      "Got correct (64.57,73.50)\n",
      "Iteration 7800, loss = 1.4052 time:9.0621\n",
      "Got correct (64.55,73.43)\n",
      "Iteration 8100, loss = 1.4607 time:9.0524\n",
      "Got correct (64.61,73.49)\n",
      "Iteration 8400, loss = 1.0092 time:9.0641\n",
      "Got correct (64.55,73.56)\n",
      "Iteration 0, loss = 1.1150 time:0.1786\n",
      "Got correct (64.65,73.58)\n",
      "Iteration 300, loss = 1.0438 time:9.0554\n",
      "Got correct (64.38,73.28)\n",
      "Iteration 600, loss = 1.0879 time:9.0481\n",
      "Got correct (64.12,73.22)\n",
      "Iteration 900, loss = 1.2011 time:9.0594\n",
      "Got correct (64.79,73.72)\n",
      "Iteration 1200, loss = 1.3194 time:9.0715\n",
      "Got correct (64.00,73.06)\n",
      "Iteration 1500, loss = 1.2001 time:9.0770\n",
      "Got correct (64.79,73.62)\n",
      "Iteration 1800, loss = 1.1497 time:9.0639\n",
      "Got correct (64.75,73.63)\n",
      "Iteration 2100, loss = 1.0094 time:9.0746\n",
      "Got correct (64.07,73.31)\n",
      "Iteration 2400, loss = 1.1311 time:9.0587\n",
      "Got correct (64.64,73.66)\n",
      "Iteration 2700, loss = 1.1247 time:9.0645\n",
      "Got correct (64.33,73.31)\n",
      "Iteration 3000, loss = 1.1514 time:9.0782\n",
      "Got correct (64.74,73.58)\n",
      "Iteration 3300, loss = 1.1120 time:9.0676\n",
      "Got correct (64.40,73.41)\n",
      "Iteration 3600, loss = 1.1911 time:9.0567\n",
      "Got correct (64.78,73.74)\n",
      "Iteration 3900, loss = 1.2310 time:9.0797\n",
      "Got correct (64.60,73.66)\n",
      "Iteration 4200, loss = 1.0098 time:9.0713\n",
      "Got correct (64.65,73.66)\n",
      "Iteration 4500, loss = 1.0460 time:9.0564\n",
      "Got correct (60.58,70.14)\n",
      "Iteration 4800, loss = 1.3526 time:9.0543\n",
      "Got correct (65.05,73.87)\n",
      "Iteration 5100, loss = 1.2704 time:9.0591\n",
      "Got correct (65.13,73.95)\n",
      "Iteration 5400, loss = 1.3905 time:9.0660\n",
      "Got correct (65.20,74.02)\n",
      "Iteration 5700, loss = 1.1862 time:9.0631\n",
      "Got correct (64.70,73.65)\n",
      "Iteration 6000, loss = 1.0889 time:9.0599\n",
      "Got correct (63.97,72.94)\n",
      "Iteration 6300, loss = 1.1641 time:9.0646\n",
      "Got correct (64.45,73.36)\n",
      "Iteration 6600, loss = 1.0927 time:9.0857\n",
      "Got correct (64.79,73.75)\n",
      "Iteration 6900, loss = 1.1225 time:9.0564\n",
      "Got correct (64.86,73.70)\n",
      "Iteration 7200, loss = 1.2036 time:9.0530\n",
      "Got correct (65.01,73.94)\n",
      "Iteration 7500, loss = 1.0394 time:9.0779\n",
      "Got correct (64.90,73.83)\n",
      "Iteration 7800, loss = 0.9826 time:9.0600\n",
      "Got correct (64.74,73.58)\n",
      "Iteration 8100, loss = 1.3516 time:9.0588\n",
      "Got correct (64.87,73.85)\n",
      "Iteration 8400, loss = 0.9887 time:9.0699\n",
      "Got correct (64.82,73.81)\n",
      "Iteration 0, loss = 1.1515 time:0.1826\n",
      "Got correct (64.87,73.77)\n",
      "Iteration 300, loss = 1.0871 time:9.0551\n",
      "Got correct (64.00,73.06)\n",
      "Iteration 600, loss = 1.1321 time:9.0505\n",
      "Got correct (64.72,73.65)\n",
      "Iteration 900, loss = 1.1256 time:9.0557\n",
      "Got correct (64.55,73.43)\n",
      "Iteration 1200, loss = 1.3579 time:9.0700\n",
      "Got correct (64.79,73.77)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1500, loss = 1.2185 time:9.0483\n",
      "Got correct (64.57,73.66)\n",
      "Iteration 1800, loss = 1.0545 time:9.0507\n",
      "Got correct (65.13,74.02)\n",
      "Iteration 2100, loss = 1.2256 time:9.0556\n",
      "Got correct (63.79,72.82)\n",
      "Iteration 2400, loss = 1.0680 time:9.0597\n",
      "Got correct (64.66,73.58)\n",
      "Iteration 2700, loss = 1.2256 time:9.0521\n",
      "Got correct (64.69,73.77)\n",
      "Iteration 3000, loss = 1.1089 time:9.0851\n",
      "Got correct (64.99,73.76)\n",
      "Iteration 3300, loss = 1.0431 time:9.0528\n",
      "Got correct (58.90,68.74)\n",
      "Iteration 3600, loss = 1.2255 time:9.0726\n",
      "Got correct (65.01,73.88)\n",
      "Iteration 3900, loss = 1.2228 time:9.0500\n",
      "Got correct (65.00,73.98)\n",
      "Iteration 4200, loss = 1.0233 time:9.0623\n",
      "Got correct (64.86,73.86)\n",
      "Iteration 4500, loss = 1.3860 time:9.0501\n",
      "Got correct (65.15,74.04)\n",
      "Iteration 4800, loss = 1.0105 time:9.0699\n",
      "Got correct (64.24,73.23)\n",
      "Iteration 5100, loss = 1.1112 time:9.0673\n",
      "Got correct (58.38,68.32)\n",
      "Iteration 5400, loss = 1.2659 time:9.0652\n",
      "Got correct (64.66,73.63)\n",
      "Iteration 5700, loss = 1.1431 time:9.0583\n",
      "Got correct (64.99,73.89)\n",
      "Iteration 6000, loss = 1.0551 time:9.0706\n",
      "Got correct (65.46,74.19)\n",
      "Iteration 6300, loss = 1.1215 time:9.0454\n",
      "Got correct (64.97,73.91)\n",
      "Iteration 6600, loss = 1.0481 time:9.0566\n",
      "Got correct (65.18,73.99)\n",
      "Iteration 6900, loss = 1.2001 time:9.0807\n",
      "Got correct (65.07,73.95)\n",
      "Iteration 7200, loss = 1.0758 time:9.0570\n",
      "Got correct (65.02,73.92)\n",
      "Iteration 7500, loss = 0.9642 time:9.0518\n",
      "Got correct (65.20,74.03)\n",
      "Iteration 7800, loss = 0.8620 time:9.0501\n",
      "Got correct (65.02,73.94)\n",
      "Iteration 8100, loss = 1.3130 time:9.0533\n",
      "Got correct (65.21,74.02)\n",
      "Iteration 8400, loss = 0.8748 time:9.0438\n",
      "Got correct (65.04,73.80)\n"
     ]
    }
   ],
   "source": [
    "train_dataset28 = QD.QDDetection(count = 40 * 3000*9 ,images_category = 3000*9,transforms = trans)\n",
    "loader_dataset28 = QD.QDDetection(count = 40 * 512,start = 3000*9, images_category = 3000)\n",
    "train_loader28 = DataLoader(dataset=train_dataset28, batch_size=128, num_workers=2, shuffle=True)\n",
    "loader_val28 = DataLoader(dataset=loader_dataset28, batch_size=128,shuffle=True)\n",
    "\n",
    "def train28(model, optimizer, epochs=1):\n",
    "    model = model.to(device=device)  # move the model parameters to CPU/GPU\n",
    "    for e in range(epochs):\n",
    "        t1 = time.time()\n",
    "        for t, (x, y) in enumerate(train_loader28):\n",
    "            model.train()  # put model to training mode\n",
    "            x = x.to(device=device, dtype=dtype)  # move to device, e.g. GPU\n",
    "            y = y.to(device=device, dtype=torch.long)\n",
    "\n",
    "            scores = model(x)\n",
    "            loss = F.cross_entropy(scores, y)\n",
    "\n",
    "            # Zero out all of the gradients for the variables which the optimizer\n",
    "            # will update.\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # This is the backwards pass: compute the gradient of the loss with\n",
    "            # respect to each  parameter of the model.\n",
    "            loss.backward()\n",
    "\n",
    "            # Actually update the parameters of the model using the gradients\n",
    "            # computed by the backwards pass.\n",
    "            optimizer.step()\n",
    "\n",
    "            t2 = time.time()\n",
    "            if t % print_every == 0:\n",
    "                print('Iteration %d, loss = %.4f time:%.4f' % (t, loss.item(),t2 - t1))\n",
    "                check_accuracy(loader_val28, model)\n",
    "                t1 = time.time()\n",
    "\n",
    "\n",
    "learning_rate28 = 1e-3\n",
    "\n",
    "def flatten(x):\n",
    "    N = x.shape[0] # read in N, C, H, W\n",
    "    return x.view(N, -1)  # \"flatten\" the C * H * W values into a single vector per image\n",
    "\n",
    "class Flatten(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return flatten(x)\n",
    "\n",
    "    \n",
    "model28 = nn.Sequential(\n",
    "    nn.Conv2d(1,64,3,padding=1),\n",
    "    nn.BatchNorm2d(64),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(64,64,3,padding=1),\n",
    "    nn.BatchNorm2d(64),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(64,128,3,padding=1),\n",
    "    nn.BatchNorm2d(128),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(128,256,3,padding=1),\n",
    "    nn.BatchNorm2d(256),\n",
    "    nn.ReLU(),\n",
    "    nn.AvgPool2d(4),\n",
    "    Flatten(),\n",
    "    nn.Linear(12544, 40),\n",
    ")\n",
    "\n",
    "# you can use Nesterov momentum in optim.SGD\n",
    "optimizer28 = optim.Adam(model28.parameters(), lr=learning_rate28)\n",
    "\n",
    "QDtrain = {\"mAP\":0,\"mAP3\":0,\"file\":\"\",\"prefix\":\"base28\"}\n",
    "train28(model28, optimizer28, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline model (96X96)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data10.npy label10.npy\n",
      "Total number of items: 120000\n",
      "data0.npy label0.npy\n",
      "Total number of items: 120000\n",
      "Epoch 0,Iteration 0, loss = 3.7450 time 0.0205\n",
      "Got correct (3.53,5.17)\n",
      "Epoch 0,Iteration 300, loss = 1.2792 time 28.0616\n",
      "Got correct (61.99,70.94)\n",
      "Epoch 0,Iteration 600, loss = 1.0423 time 28.0804\n",
      "Got correct (69.12,77.29)\n",
      "Epoch 0,Iteration 900, loss = 1.0038 time 28.0575\n",
      "Got correct (71.35,79.32)\n",
      "data1.npy label1.npy\n",
      "Total number of items: 120000\n",
      "Epoch 0,Iteration 0, loss = 0.8431 time 0.0176\n",
      "Got correct (72.17,79.73)\n",
      "Epoch 0,Iteration 300, loss = 0.8628 time 28.0100\n",
      "Got correct (74.15,81.44)\n",
      "Epoch 0,Iteration 600, loss = 0.8026 time 28.0134\n",
      "Got correct (75.27,82.31)\n",
      "Epoch 0,Iteration 900, loss = 0.7856 time 28.0212\n",
      "Got correct (75.58,82.67)\n",
      "data2.npy label2.npy\n",
      "Total number of items: 120000\n",
      "Epoch 0,Iteration 0, loss = 1.1083 time 0.0173\n",
      "Got correct (75.21,82.32)\n",
      "Epoch 0,Iteration 300, loss = 0.7144 time 28.0192\n",
      "Got correct (75.46,82.66)\n",
      "Epoch 0,Iteration 600, loss = 0.9568 time 27.9897\n",
      "Got correct (76.98,83.69)\n",
      "Epoch 0,Iteration 900, loss = 0.9771 time 28.0028\n",
      "Got correct (77.06,83.77)\n",
      "data3.npy label3.npy\n",
      "Total number of items: 120000\n",
      "Epoch 0,Iteration 0, loss = 0.7989 time 0.0173\n",
      "Got correct (76.47,83.33)\n",
      "Epoch 0,Iteration 300, loss = 0.9094 time 27.9528\n",
      "Got correct (77.65,84.15)\n",
      "Epoch 0,Iteration 600, loss = 0.6793 time 27.9873\n",
      "Got correct (77.46,84.14)\n",
      "Epoch 0,Iteration 900, loss = 0.9513 time 27.9802\n",
      "Got correct (78.01,84.57)\n",
      "data0.npy label0.npy\n",
      "Total number of items: 120000\n",
      "Epoch 1,Iteration 0, loss = 0.7271 time 0.0170\n",
      "Got correct (77.87,84.44)\n",
      "Epoch 1,Iteration 300, loss = 0.8325 time 27.9398\n",
      "Got correct (78.44,84.82)\n",
      "Epoch 1,Iteration 600, loss = 0.6780 time 27.9442\n",
      "Got correct (78.38,84.81)\n",
      "Epoch 1,Iteration 900, loss = 0.6970 time 27.9588\n",
      "Got correct (79.15,85.35)\n",
      "data1.npy label1.npy\n",
      "Total number of items: 120000\n",
      "Epoch 1,Iteration 0, loss = 0.8054 time 0.0178\n",
      "Got correct (78.93,85.24)\n",
      "Epoch 1,Iteration 300, loss = 0.7092 time 27.9185\n",
      "Got correct (78.85,85.25)\n",
      "Epoch 1,Iteration 600, loss = 0.6878 time 27.9683\n",
      "Got correct (79.28,85.51)\n",
      "Epoch 1,Iteration 900, loss = 0.5689 time 27.9279\n",
      "Got correct (79.78,85.82)\n",
      "data2.npy label2.npy\n",
      "Total number of items: 120000\n",
      "Epoch 1,Iteration 0, loss = 0.7213 time 0.0172\n",
      "Got correct (79.66,85.78)\n",
      "Epoch 1,Iteration 300, loss = 0.6964 time 27.9365\n",
      "Got correct (79.83,85.97)\n",
      "Epoch 1,Iteration 600, loss = 0.6878 time 27.9136\n",
      "Got correct (79.03,85.37)\n",
      "Epoch 1,Iteration 900, loss = 0.4304 time 27.9084\n",
      "Got correct (79.29,85.54)\n",
      "data3.npy label3.npy\n",
      "Total number of items: 120000\n",
      "Epoch 1,Iteration 0, loss = 0.6167 time 0.0172\n",
      "Got correct (79.51,85.73)\n",
      "Epoch 1,Iteration 300, loss = 0.5346 time 27.8829\n",
      "Got correct (79.84,85.95)\n",
      "Epoch 1,Iteration 600, loss = 0.6762 time 27.9096\n",
      "Got correct (79.49,85.73)\n",
      "Epoch 1,Iteration 900, loss = 0.6882 time 27.9151\n",
      "Got correct (79.79,85.95)\n",
      "data0.npy label0.npy\n",
      "Total number of items: 120000\n",
      "Epoch 2,Iteration 0, loss = 0.5801 time 0.0174\n",
      "Got correct (80.11,86.20)\n",
      "Epoch 2,Iteration 300, loss = 0.4204 time 27.8777\n",
      "Got correct (80.04,86.08)\n",
      "Epoch 2,Iteration 600, loss = 0.5542 time 27.8923\n",
      "Got correct (80.09,86.01)\n",
      "Epoch 2,Iteration 900, loss = 0.5825 time 27.8961\n",
      "Got correct (79.97,86.20)\n",
      "data1.npy label1.npy\n",
      "Total number of items: 120000\n",
      "Epoch 2,Iteration 0, loss = 0.5000 time 0.0171\n",
      "Got correct (80.50,86.39)\n",
      "Epoch 2,Iteration 300, loss = 0.6874 time 27.8775\n",
      "Got correct (79.96,86.11)\n",
      "Epoch 2,Iteration 600, loss = 0.5042 time 27.8949\n",
      "Got correct (80.20,86.29)\n",
      "Epoch 2,Iteration 900, loss = 0.5658 time 27.8744\n",
      "Got correct (80.48,86.45)\n",
      "data2.npy label2.npy\n",
      "Total number of items: 120000\n",
      "Epoch 2,Iteration 0, loss = 0.5444 time 0.0173\n",
      "Got correct (79.90,86.05)\n",
      "Epoch 2,Iteration 300, loss = 0.6076 time 27.8521\n",
      "Got correct (80.47,86.41)\n",
      "Epoch 2,Iteration 600, loss = 0.6457 time 27.8508\n",
      "Got correct (80.52,86.39)\n",
      "Epoch 2,Iteration 900, loss = 0.4298 time 27.8390\n",
      "Got correct (80.37,86.40)\n",
      "data3.npy label3.npy\n",
      "Total number of items: 120000\n",
      "Epoch 2,Iteration 0, loss = 0.5995 time 0.0173\n",
      "Got correct (80.23,86.18)\n",
      "Epoch 2,Iteration 300, loss = 0.4056 time 27.8313\n",
      "Got correct (80.53,86.48)\n",
      "Epoch 2,Iteration 600, loss = 0.6506 time 27.8524\n",
      "Got correct (80.40,86.35)\n",
      "Epoch 2,Iteration 900, loss = 0.4164 time 27.8864\n",
      "Got correct (80.67,86.53)\n",
      "data0.npy label0.npy\n",
      "Total number of items: 120000\n",
      "Epoch 3,Iteration 0, loss = 0.6108 time 0.0170\n",
      "Got correct (80.35,86.38)\n",
      "Epoch 3,Iteration 300, loss = 0.4296 time 27.8372\n",
      "Got correct (80.42,86.42)\n",
      "Epoch 3,Iteration 600, loss = 0.6874 time 27.8557\n",
      "Got correct (80.37,86.37)\n",
      "Epoch 3,Iteration 900, loss = 0.5363 time 27.8499\n",
      "Got correct (80.60,86.50)\n",
      "data1.npy label1.npy\n",
      "Total number of items: 120000\n",
      "Epoch 3,Iteration 0, loss = 0.5098 time 0.0171\n",
      "Got correct (80.62,86.55)\n",
      "Epoch 3,Iteration 300, loss = 0.5790 time 27.8074\n",
      "Got correct (80.42,86.37)\n",
      "Epoch 3,Iteration 600, loss = 0.4749 time 27.8646\n",
      "Got correct (80.48,86.45)\n",
      "Epoch 3,Iteration 900, loss = 0.3786 time 27.8564\n",
      "Got correct (80.05,86.15)\n",
      "data2.npy label2.npy\n",
      "Total number of items: 120000\n",
      "Epoch 3,Iteration 0, loss = 0.6035 time 0.0170\n",
      "Got correct (80.22,86.17)\n",
      "Epoch 3,Iteration 300, loss = 0.5679 time 27.8363\n",
      "Got correct (80.36,86.33)\n",
      "Epoch 3,Iteration 600, loss = 0.4767 time 27.8387\n",
      "Got correct (80.05,86.04)\n",
      "Epoch 3,Iteration 900, loss = 0.5762 time 27.8255\n",
      "Got correct (80.31,86.21)\n",
      "data3.npy label3.npy\n",
      "Total number of items: 120000\n",
      "Epoch 3,Iteration 0, loss = 0.3944 time 0.0171\n",
      "Got correct (80.42,86.37)\n",
      "Epoch 3,Iteration 300, loss = 0.5031 time 27.8300\n",
      "Got correct (80.25,86.27)\n",
      "Epoch 3,Iteration 600, loss = 0.3517 time 27.8217\n",
      "Got correct (80.28,86.33)\n",
      "Epoch 3,Iteration 900, loss = 0.3662 time 27.8172\n",
      "Got correct (80.39,86.35)\n",
      "data0.npy label0.npy\n",
      "Total number of items: 120000\n",
      "Epoch 4,Iteration 0, loss = 0.5472 time 0.0172\n",
      "Got correct (80.24,86.14)\n",
      "Epoch 4,Iteration 300, loss = 0.4549 time 27.8022\n",
      "Got correct (80.10,86.08)\n",
      "Epoch 4,Iteration 600, loss = 0.4516 time 27.8093\n",
      "Got correct (80.27,86.18)\n",
      "Epoch 4,Iteration 900, loss = 0.2856 time 27.8541\n",
      "Got correct (80.20,86.19)\n",
      "data1.npy label1.npy\n",
      "Total number of items: 120000\n",
      "Epoch 4,Iteration 0, loss = 0.6269 time 0.0171\n",
      "Got correct (80.56,86.40)\n",
      "Epoch 4,Iteration 300, loss = 0.3664 time 27.8026\n",
      "Got correct (80.22,86.20)\n",
      "Epoch 4,Iteration 600, loss = 0.4322 time 27.8359\n",
      "Got correct (79.79,85.89)\n",
      "Epoch 4,Iteration 900, loss = 0.5512 time 27.8147\n",
      "Got correct (80.07,86.04)\n",
      "data2.npy label2.npy\n",
      "Total number of items: 120000\n",
      "Epoch 4,Iteration 0, loss = 0.4843 time 0.0172\n",
      "Got correct (80.28,86.22)\n",
      "Epoch 4,Iteration 300, loss = 0.4506 time 27.7968\n",
      "Got correct (79.96,86.01)\n",
      "Epoch 4,Iteration 600, loss = 0.4966 time 27.8001\n",
      "Got correct (80.33,86.23)\n",
      "Epoch 4,Iteration 900, loss = 0.3664 time 27.8297\n",
      "Got correct (79.86,85.85)\n",
      "data3.npy label3.npy\n",
      "Total number of items: 120000\n",
      "Epoch 4,Iteration 0, loss = 0.3918 time 0.0173\n",
      "Got correct (80.17,86.14)\n",
      "Epoch 4,Iteration 300, loss = 0.4306 time 27.8168\n",
      "Got correct (80.06,86.05)\n",
      "Epoch 4,Iteration 600, loss = 0.3251 time 27.8070\n",
      "Got correct (79.61,85.70)\n",
      "Epoch 4,Iteration 900, loss = 0.2724 time 27.8069\n",
      "Got correct (80.26,86.12)\n"
     ]
    }
   ],
   "source": [
    "base_learning_rate = 1e-4\n",
    "\n",
    "def flatten(x):\n",
    "    N = x.shape[0] # read in N, C, H, W\n",
    "    return x.view(N, -1)  # \"flatten\" the C * H * W values into a single vector per image\n",
    "\n",
    "class Flatten(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return flatten(x)\n",
    "\n",
    "    \n",
    "base_model = nn.Sequential(\n",
    "    nn.Conv2d(1,64,3,stride = 1,padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(64,128,3,stride = 2,padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(128,128,3,stride = 1,padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(3,stride = 2,padding = 1),\n",
    "    nn.Conv2d(128,256,3,stride = 2,padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(256,256,3,stride = 1,padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(3,stride = 2,padding = 1),\n",
    "    Flatten(),\n",
    "    nn.Linear(9216,4096),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(4096,40)\n",
    ")\n",
    "\n",
    "\n",
    "base_optimizer = optim.Adam(base_model.parameters(),lr=base_learning_rate)\n",
    "QDtrain = {\"mAP\":0,\"mAP3\":0,\"file\":\"\",\"prefix\":\"base96\"}\n",
    "train(base_model, base_optimizer, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sketch-A-Net model(256 X 256)\n",
    "* The following code is based on Sketch-A-Net that Beats Humans."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/40 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total class number:40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-939c661c12c8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_dataset_sn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mQD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mQDStrokeDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m40\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m3000\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mimages_category\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m3000\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtransforms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrans\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mloader_dataset_sn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mQD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mQDStrokeDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m40\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m3000\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimages_category\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m3000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtrain_loader_sn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_dataset_sn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mloader_val_sn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mloader_dataset_sn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/kaggle/project/QDdata.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, class_names, data_dir, output, start, count, images_category, image_size, transforms)\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcat_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m                     \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreshape_to_square\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstrokes_to_npy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimage_size\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m                     \u001b[0mwhole_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtotal\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m                     \u001b[0mlabel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtotal\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/kaggle/project/QDdata.py\u001b[0m in \u001b[0;36mstrokes_to_npy\u001b[0;34m(strokes)\u001b[0m\n\u001b[1;32m     57\u001b[0m                 \u001b[0mimg\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mA\u001b[0m \u001b[0mgrayscale\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0mD\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0marray\u001b[0m \u001b[0mrepresentation\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0msketch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \t\"\"\"\n\u001b[0;32m---> 59\u001b[0;31m         \u001b[0mmin_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_bounds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstrokes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m         \u001b[0mdims\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m50\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmax_x\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mmin_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m50\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmax_y\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mmin_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/kaggle/project/QDdata.py\u001b[0m in \u001b[0;36mget_bounds\u001b[0;34m(strokes)\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0mabs_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mabs_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstrokes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m                 \u001b[0mdx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstrokes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m                 \u001b[0mabs_x\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mdx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "train_dataset_sn = QD.QDStrokeDataset(count = 40 * 3000 ,images_category = 3000*9,transforms = trans)\n",
    "loader_dataset_sn = QD.QDStrokeDataset(count = 40 * 512,start = 3000*9, images_category = 3000)\n",
    "train_loader_sn = DataLoader(dataset=train_dataset_sn, batch_size=128, num_workers=2, shuffle=True)\n",
    "loader_val_sn = DataLoader(dataset=loader_dataset_sn, batch_size=128,shuffle=True)\n",
    "\n",
    "SN_learning_rate = 1e-3\n",
    "\n",
    "def flatten(x):\n",
    "    N = x.shape[0] # read in N, C, H, W\n",
    "    return x.view(N, -1)  # \"flatten\" the C * H * W values into a single vector per image\n",
    "\n",
    "class Flatten(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return flatten(x)\n",
    "\n",
    "    \n",
    "SN_model = nn.Sequential(\n",
    "    nn.Conv2d(1,64,15,stride = 3,padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(3,stride = 2,padding = 0),\n",
    "    \n",
    "    nn.Conv2d(35,128,5,stride = 1,padding=0),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(3,stride = 2,padding = 0),\n",
    "    \n",
    "    nn.Conv2d(15,256,3,stride = 1,padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(15,256,3,stride = 1,padding=1),\n",
    "    nn.ReLU(),    \n",
    "    nn.Conv2d(15,256,3,stride = 1,padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(3,stride = 2,padding = 0),\n",
    "\n",
    "    Flatten(),\n",
    "    nn.Linear(256*7*7,512),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(),\n",
    "    \n",
    "    nn.Linear(512,512),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(),\n",
    "    \n",
    "    nn.Linear(512,40)\n",
    ")\n",
    "\n",
    "\n",
    "SN_optimizer = optim.Adam(SN_model.parameters(),weight_decay = 1e-5,lr=SN_learning_rate)\n",
    "QDtrain = {\"mAP\":0,\"mAP3\":0,\"file\":\"\",\"prefix\":\"sketchanet\"}\n",
    "train(SN_model, SN_optimizer, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run test samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def evaluate_test(test_data, model,y):\n",
    "    model.eval()  # set model to evaluation mode\n",
    "    with torch.no_grad():\n",
    "        meanAP = []\n",
    "        meanAP3 = []\n",
    "        for i ,x in enumerate(test_data):\n",
    "            x = x.to(device=device, dtype=dtype)  # move to device, e.g. GPU\n",
    "            #y = y_label.to(device=device, dtype=torch.long)\n",
    "            y_pred = model(x)\n",
    "            y_val = y.reshape(-1,1)\n",
    "            y_pred = y_pred.data.cpu().numpy()\n",
    "            \n",
    "            mAP = 100 * mean_ap_3(y_val,y_pred,1)\n",
    "            mAP3 = 100 * mean_ap_3(y_val,y_pred,3)\n",
    "            meanAP.append(mAP)\n",
    "            meanAP3.append(mAP3)\n",
    "        \n",
    "        m1 = np.mean(meanAP)\n",
    "        m3 = np.mean(meanAP3)\n",
    "        return (m1,m3)\n",
    "\n",
    "model = base_model.to(device=device)\n",
    "checkpoint = torch.load(\"model_parameter99.3972598.87986\")\n",
    "model.load_state_dict(checkpoint)\n",
    "\n",
    "class_name = QD.QDloadtest(name = \"./data1.npy\")\n",
    "class_name = class_name.class_names\n",
    "\n",
    "class_accuracy = []\n",
    "\n",
    "for i,name in enumerate(tqdm(class_name)):\n",
    "    test_data = QD.QDloadtest(name=os.path.join(\"../cs230/pic96\",name+\".npz\"),image_size=(96,96))\n",
    "    test_loader = DataLoader(dataset=test_data, batch_size=128, num_workers=2, shuffle=False)\n",
    "    y = np.ones(len(test_data))*i\n",
    "    m1,m3 = evaluate_test(test_loader,model,y)\n",
    "    print(name,m1,m3)\n",
    "    class_accuracy.append((name,str(m1),str(m3)))\n",
    "    \n",
    "with open('class_accuracy.csv',\"w+\") as fp:\n",
    "    writer = csv.writer(fp, delimiter=',')\n",
    "    writer.writerow([\"class\", \"meanAP1\", \"meanAP3\"])  # write header\n",
    "    writer.writerows(class_accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) 96*96, resnet50, epoch 10, GSD. 75.2%\n",
    "2) 96*96, resnet50, epoch 10, GSD  79.9% model_parametertensor(91.6667)\n",
    "3) 96*96, resnet50, epoch 10, Adam model_resnet_92.317_90\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* convert simplified test dataset to pixel drawsing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the accuracy based on the class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create test_simplified.\n",
    "load compressed(96*96) 1.968482494354248\n",
    "load non compressed(96*96)  0.31299567222595215\n",
    "load non compressed(28*28) 0.04715704917907715\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10,11):\n",
    "    data = QD.QDcreateData()\n",
    "    data.create(start=i*3000,dir_name=\"../cs230/pic96\")\n",
    "    del data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
