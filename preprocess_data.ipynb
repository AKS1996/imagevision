{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocese the data\n",
    "* Reduce some data based on entropy value. Its aim is to remove too simple images and too many strokes images.\n",
    "* Create the validate and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from dask import bag\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import os\n",
    "import datetime as dt\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import ast\n",
    "\n",
    "%matplotlib inline\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following code written by beluga from Kaggle  https://www.kaggle.com/gaborfodor/shuffle-csvs\n",
    "qd_names =['cup','garden hose', 'marker', 'truck', 'oven', 'cooler', 'birthday cake',\n",
    "'camouflage', 'pool', 'dog', 'bear','bird', 'The Great Wall of China','van',\n",
    "'tiger', 'bench', 'pickup truck','coffee cup', 'telephone', 'mug','matches',\n",
    "'animal migration', 'lantern', 'skyscraper','keyboard','foot','monkey','sleeping bag',\n",
    "'brain', 'peanut', 'belt', 'tent','cookie', 'cake','hot dog',\n",
    "'violin', 'cello', 'donut', 'hourglass', 'bee']\n",
    "\n",
    "test_dir = './test'\n",
    "train_dir = './train'\n",
    "val_dir = './val'\n",
    "\n",
    "def f2cat(filename: str) -> str:\n",
    "    return filename.split('.')[0]\n",
    "\n",
    "class Simplified():\n",
    "    def __init__(self, input_path='./input'):\n",
    "        self.input_path = input_path\n",
    "\n",
    "    def list_all_categories(self):\n",
    "        return qd_names\n",
    "\n",
    "    def read_training_csv(self, category, nrows=None, usecols=None, drawing_transform=False):\n",
    "        df = pd.read_csv(os.path.join(self.input_path, 'train_simplified', category + '.csv'),\n",
    "                         nrows=nrows,parse_dates=['timestamp'], usecols=usecols)\n",
    "        if drawing_transform:\n",
    "            df['drawing'] = df['drawing'].apply(json.loads)\n",
    "        return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n"
     ]
    }
   ],
   "source": [
    "start = dt.datetime.now()\n",
    "s = Simplified()\n",
    "NCSVS = 20\n",
    "categories = s.list_all_categories()\n",
    "print(len(categories))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create  0  category: cup  len 130721\n",
      "After entropy 117647 117647 0.029724729240144854 3.3831330513979117\n",
      "Create  1  category: garden hose  len 121843\n",
      "After entropy 109657 109657 0.010447537330226785 3.2984964422329606\n",
      "Create  2  category: marker  len 319136\n",
      "After entropy 287222 287222 0.009296104804529342 3.314858570868997\n",
      "Create  3  category: truck  len 131354\n",
      "After entropy 118218 118218 0.010881565108004563 3.2473362819853278\n",
      "Create  4  category: oven  len 206910\n",
      "After entropy 186218 186218 0.009079090915640454 3.3383356880539363\n",
      "Create  5  category: cooler  len 271444\n",
      "After entropy 244298 244298 0.009079090915640454 3.6545267006446074\n",
      "Create  6  category: birthday cake  len 144982\n",
      "After entropy 130482 130482 0.010447537330226785 2.81485625247105\n",
      "Create  7  category: camouflage  len 172710\n",
      "After entropy 155438 155438 0.009079090915640454 4.00447336980575\n",
      "Create  8  category: pool  len 133439\n",
      "After entropy 120095 120095 0.009079090915640454 3.28680916582468\n",
      "Create  9  category: dog  len 152159\n",
      "After entropy 136943 136943 0.04292675230961114 3.3343141396130633\n",
      "Create  10  category: bear  len 134762\n",
      "After entropy 121284 121284 0.009079090915640454 3.312103987500784\n",
      "Create  11  category: bird  len 133572\n",
      "After entropy 120214 120214 0.03932972480782286 3.125676553794183\n",
      "Create  12  category: The Great Wall of China  len 193015\n",
      "After entropy 173713 173713 0.009079090915640454 3.90668842959135\n",
      "Create  13  category: van  len 165909\n",
      "After entropy 149317 149317 0.009079090915640454 4.031840377612303\n",
      "Create  14  category: tiger  len 121067\n",
      "After entropy 108959 108959 0.010881565108004563 3.25336887263564\n",
      "Create  15  category: bench  len 128695\n",
      "After entropy 115825 115825 0.01353649640251481 3.0341688991752926\n",
      "Create  16  category: pickup truck  len 130740\n",
      "After entropy 117666 117666 0.010447537330226785 3.128218706430132\n",
      "Create  17  category: coffee cup  len 183432\n",
      "After entropy 165088 165088 0.009079090915640454 3.3894642113402567\n",
      "Create  18  category: telephone  len 127885\n",
      "After entropy 115095 115095 0.009079090915640454 2.9845991510058436\n",
      "Create  19  category: mug  len 152918\n",
      "After entropy 137626 137626 0.009079090915640454 3.868098653356687\n",
      "Create  20  category: matches  len 143969\n",
      "After entropy 129571 129571 0.010881565108004563 3.198393633476984\n",
      "Create  21  category: animal migration  len 137847\n",
      "After entropy 124061 124061 0.010447537330226785 3.701584025035589\n",
      "Create  22  category: lantern  len 149912\n",
      "After entropy 134920 134920 0.009079090915640454 3.676013644118173\n",
      "Create  23  category: skyscraper  len 183709\n",
      "After entropy 165337 165337 0.009079090915640454 3.601336579850157\n",
      "Create  24  category: keyboard  len 187766\n",
      "After entropy 168988 168988 0.010447537330226785 3.3698971694145943\n",
      "Create  25  category: foot  len 203086\n",
      "After entropy 182776 182776 0.010881565108004563 3.20831565335079\n",
      "Create  26  category: monkey  len 127633\n",
      "After entropy 114869 114869 0.010447537330226785 3.388070608357948\n",
      "Create  27  category: sleeping bag  len 119691\n",
      "After entropy 107721 107721 0.009079090915640454 3.1812222300551163\n",
      "Create  28  category: brain  len 143033\n",
      "After entropy 128729 128729 0.010881565108004563 3.857658763022078\n",
      "Create  29  category: peanut  len 126626\n",
      "After entropy 113962 113962 0.010881565108004563 3.858638425073598\n",
      "Create  30  category: belt  len 191119\n",
      "After entropy 172007 172007 0.009079090915640454 3.1333338593928355\n",
      "Create  31  category: tent  len 131527\n",
      "After entropy 118373 118373 0.021762297272167004 3.0550814478893615\n",
      "Create  32  category: cookie  len 131353\n",
      "After entropy 118217 118217 0.010881565108004563 3.0664902066811255\n",
      "Create  33  category: cake  len 124905\n",
      "After entropy 112413 112413 0.009296104804529342 3.1762079842649165\n",
      "Create  34  category: hot dog  len 181999\n",
      "After entropy 163799 163799 0.021762297272167004 3.0434461987740966\n",
      "Create  35  category: violin  len 217260\n",
      "After entropy 195534 195534 0.010881565108004563 3.726838973467019\n",
      "Create  36  category: cello  len 149725\n",
      "After entropy 134751 134751 0.010447537330226785 3.784380735639734\n",
      "Create  37  category: donut  len 140751\n",
      "After entropy 126675 126675 0.010881565108004563 3.8308631862858604\n",
      "Create  38  category: hourglass  len 135957\n",
      "After entropy 122361 122361 0.009079090915640454 3.622582229144041\n",
      "Create  39  category: bee  len 120890\n",
      "After entropy 108800 108800 0.0129673652721072 2.7751979753637146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 1/20 [00:04<01:25,  4.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(281600, 7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|█         | 2/20 [00:08<01:19,  4.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(280576, 7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 15%|█▌        | 3/20 [00:12<01:12,  4.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(280576, 7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|██        | 4/20 [00:16<01:07,  4.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(280576, 7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|██▌       | 5/20 [00:20<01:02,  4.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(281600, 7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|███       | 6/20 [00:24<00:57,  4.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(280576, 7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 35%|███▌      | 7/20 [00:36<01:22,  6.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(281600, 7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████      | 8/20 [00:54<01:59,  9.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(281600, 7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 45%|████▌     | 9/20 [00:58<01:29,  8.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(282624, 7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████     | 10/20 [01:07<01:22,  8.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(281600, 7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 55%|█████▌    | 11/20 [01:25<01:41, 11.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(281600, 7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|██████    | 12/20 [01:29<01:12,  9.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(280576, 7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 65%|██████▌   | 13/20 [01:36<01:00,  8.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(280576, 7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|███████   | 14/20 [01:46<00:53,  8.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(280576, 7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 75%|███████▌  | 15/20 [01:51<00:38,  7.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(281600, 7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|████████  | 16/20 [01:56<00:27,  6.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(280576, 7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 85%|████████▌ | 17/20 [02:00<00:18,  6.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(281600, 7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|█████████ | 18/20 [02:04<00:11,  5.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(281600, 7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 95%|█████████▌| 19/20 [02:09<00:05,  5.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(281600, 7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|██████████| 20/20 [02:13<00:00,  4.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(281600, 7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "low_threshold = 5\n",
    "upper_threshold = 5\n",
    "\n",
    "def entropy_it(x):\n",
    "    counts = np.bincount(x)\n",
    "    p = counts[counts > 0] / float(len(x))\n",
    "    return -np.sum(p * np.log2(p))\n",
    "\n",
    "def data_draw_cv2(raw_strokes, size=96, linewidth=6, time_color=True):\n",
    "    img = np.zeros((256, 256), np.uint8)\n",
    "    for t, stroke in enumerate(ast.literal_eval(raw_strokes)):\n",
    "        for i in range(len(stroke[0]) - 1):\n",
    "            color = 255 - min(t, 10) * 13 if time_color else 255\n",
    "            _ = cv2.line(img, (stroke[0][i], stroke[1][i]), \n",
    "                         (stroke[0][i + 1], stroke[1][i + 1]), color, linewidth)\n",
    "    if size != 256:\n",
    "        img = cv2.resize(img, (size, size))\n",
    "        \n",
    "    img = np.array(img)\n",
    "    return entropy_it(img.flatten()), img\n",
    "\n",
    "def create_dataset(recognized_only = False ):\n",
    "    for y, cat in enumerate(categories):\n",
    "        df = s.read_training_csv(cat)\n",
    "        df = df[df['recognized'] == True].copy() if recognized_only else df\n",
    "        #Shuffle the data of the category.\n",
    "        print(\"Create \",y,\" category:\",cat,\" len\",len(df))\n",
    "        df['rnd'] = np.random.rand(len(df))\n",
    "        df = df.sort_values(by='rnd').drop('rnd', axis=1)\n",
    "\n",
    "        entropybag = bag.from_sequence(df.drawing.values).map(data_draw_cv2)\n",
    "        data = entropybag.compute()\n",
    "        entropy, images = zip(*data)\n",
    "        lower = np.percentile(entropy, low_threshold)\n",
    "        upper = np.percentile(entropy, 100 - upper_threshold)    \n",
    "        df['y'] = y\n",
    "\n",
    "        df['cv'] = entropy\n",
    "\n",
    "        df = df[(df['cv'] > lower) & (df['cv'] < upper)]\n",
    "        index = np.where((entropy > lower) & (entropy < upper))\n",
    "\n",
    "        images = np.array(images)\n",
    "        images = images[index]\n",
    "\n",
    "        print(\"After entropy\",len(df),len(images),min(entropy),max(entropy))\n",
    "\n",
    "        #Create test dataset, val dataset, and train dataset.\n",
    "        test_csv = df[0:512]\n",
    "        val_csv = df[512:1024]\n",
    "        df = df[1024:]\n",
    "        \n",
    "        df['cv'] = (df.key_id // 10 ** 7) % NCSVS\n",
    "        \n",
    "        if y == 0:\n",
    "            #np.save(os.path.join(test_dir,cat),images[0:512])\n",
    "            #np.save(os.path.join(val_csv,cat),images[0:512])\n",
    "            test_csv.to_csv(os.path.join(test_dir,'test_dataset.csv'),index=False)\n",
    "            val_csv.to_csv(os.path.join(val_dir,'val_dataset.csv'),index = False)\n",
    "        else:\n",
    "            test_csv.to_csv(os.path.join(test_dir,'test_dataset.csv'),mode = 'a',header = False, index=False)\n",
    "            val_csv.to_csv(os.path.join(val_dir,'val_dataset.csv'),mode = 'a',header = False, index=False)\n",
    "            \n",
    "        df.to_csv(os.path.join(train_dir,cat + \".csv\"),index=False)\n",
    "        \n",
    "        for k in range(NCSVS):\n",
    "            filename = 'train_k{}.csv'.format(k)\n",
    "            chunk = df[df.cv == k]\n",
    "            chunk = chunk.drop(['key_id'], axis=1)\n",
    "            if y == 0:\n",
    "                #np.save(os.path.join(train_dir,cat),images[1024:])\n",
    "                chunk.to_csv(os.path.join(train_dir,filename),index=False)\n",
    "            else:\n",
    "                chunk.to_csv(os.path.join(train_dir,filename),mode = 'a',header = False, index=False)\n",
    "\n",
    "create_dataset()\n",
    "\n",
    "for k in tqdm(range(NCSVS)):\n",
    "\n",
    "    filename = os.path.join(train_dir,'train_k{}.csv'.format(k))\n",
    "    if os.path.exists(filename):\n",
    "        df = pd.read_csv(filename)\n",
    "        df['rnd'] = np.random.rand(len(df))\n",
    "        df = df.sort_values(by='rnd').drop('rnd', axis=1)\n",
    "        length = len(df)\n",
    "        length = (length // 1024)*1024\n",
    "        df = df[:length]\n",
    "        df.to_csv(filename, index=False)\n",
    "        #os.remove(filename)\n",
    "        print(df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
