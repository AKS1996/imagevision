{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quick Drawing is a kaggle challenge for classifying the sketch pictures. The total number of category is 340 and \n",
    "there are 50M pictures in the dataset. Each catogory has 25,000 pictures. The difficulty is the drawing might be \n",
    "incomplete or the drawing does not match the label. We are trying to develop a CNN to solve the issue.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the challenge, there are 4 kinds of dataset. \n",
    "\n",
    "    - Raw data (.ndjson)\n",
    "    - Simplified drawings (.ndjson)\n",
    "    - Binary data (.bin)\n",
    "    - Bitmap data (.npy)\n",
    "Raw data and Simplified drawings are provided in a vector information of strokes. Bitmap data is rendered into \n",
    "28 * 28 grayscale bitmap in the numpy format.  \n",
    "\n",
    "Maybe we could consider the raw data to improve the performance since it inlcudes the sequence information.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import time\n",
    "import torch\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import sampler\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as T\n",
    "import numpy as np\n",
    "from torch.utils import data\n",
    "import QDdata as QD\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from torch.utils.data import DataLoader\n",
    "import resnet as RN\n",
    "from torchvision import transforms\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device: cuda\n"
     ]
    }
   ],
   "source": [
    "USE_GPU = True\n",
    "\n",
    "dtype = torch.float32 # we will be using float throughout this tutorial\n",
    "\n",
    "if USE_GPU and torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "# Constant to control how frequently we print train loss\n",
    "print_every = 75\n",
    "\n",
    "print('using device:', device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans = transforms.Compose([transforms.RandomHorizontalFlip(0.5), transforms.ToTensor()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Center Feature Per Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.01\n",
    "cf_class = torch.from_numpy(np.load(\"center_feature.npy\"))\n",
    "cf_class = cf_class.to(device=device, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\"learning_rate\" : 3e-3}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following code comes from https://github.com/pytorch/examples/blob/master/imagenet/main.py\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "def adjust_learning_rate(optimizer, epoch, args):\n",
    "    \"\"\"Sets the learning rate to the initial LR decayed by 10 every 30 epochs\"\"\"\n",
    "    lr = args['learning_rate'] * (0.5 ** epoch )\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr\n",
    "\n",
    "def accuracy(output, target, topk=(1,)):\n",
    "    \"\"\"Computes the accuracy over the k top predictions for the specified values of k\"\"\"\n",
    "    with torch.no_grad():\n",
    "        maxk = max(topk)\n",
    "        batch_size = target.size(0)\n",
    "\n",
    "        _, pred = output.topk(maxk, 1, True, True)\n",
    "        pred = pred.t()\n",
    "        correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "        res = []\n",
    "        for k in topk:\n",
    "            correct_k = correct[:k].view(-1).float().sum(0, keepdim=True)\n",
    "            res.append(correct_k.mul_(100.0 / batch_size))\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SketchRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, dropout = 0.1, n_layers=1):\n",
    "        super(SketchRNN, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "        self.conv1d_1 = nn.Conv1d(input_size, 48, 5)\n",
    "        self.dropout_1 = nn.Dropout(0.1)\n",
    "        self.conv1d_2 = nn.Conv1d(48, 64, 5)\n",
    "        self.dropout_2 = nn.Dropout(0.1)\n",
    "        self.conv1d_3 = nn.Conv1d(64, 96, 3)\n",
    "        self.dropout_3 = nn.Dropout(0.1)\n",
    "        self.lstm_1 = nn.LSTM(96,hidden_size, n_layers, dropout,batch_first=True,bidirectional=True)\n",
    "        self.fc_mu = nn.Linear(hidden_size*186*2, output_size)        \n",
    "\n",
    "    def forward(self, inputs, hidden):\n",
    "        inputs = inputs.transpose(1, 2)\n",
    "        \n",
    "        output = self.conv1d_1(inputs)\n",
    "        output = self.dropout_1(output)\n",
    "        output = self.conv1d_2(output)\n",
    "        output = self.dropout_2(output)\n",
    "        output = self.conv1d_3(output)\n",
    "        output = self.dropout_3(output)\n",
    "        output = output.transpose(1, 2)\n",
    "        \n",
    "        output, (hidden,x) = self.lstm_1(output, hidden)\n",
    "        \n",
    "        output = output.contiguous()\n",
    "        output = output.view(output.size(0),-1)\n",
    "        output = self.fc_mu(output)\n",
    "        output = F.log_softmax(output, dim=1)\n",
    "        return output, hidden "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resnet50 96X96"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### The following codes comes from cs231N.\n",
    "from average_precision import mapk\n",
    "def mean_ap_torch(y_val,y_pred_score,k):\n",
    "    y_pred = [torch.sort(c,descending=True)[::-1][1][:k] for c in y_pred_score]\n",
    "    return mapk(y_val,y_pred,k)\n",
    "\n",
    "def mean_ap_3(y_val,y_pred_score,k):\n",
    "    y_pred = [np.argsort(c)[::-1][:k] for c in y_pred_score]\n",
    "    return mapk(y_val,y_pred,k)\n",
    "\n",
    "def check_accuracy(loader, model):\n",
    "    \n",
    "    model.eval()  # set model to evaluation mode\n",
    "    \n",
    "    meanAP = []\n",
    "    meanAP3 = []\n",
    "    with torch.no_grad():\n",
    "        for i ,(x,stroke, y) in enumerate(loader):\n",
    "            x = x.to(device=device, dtype=dtype)  # move to device, e.g. GPU\n",
    "            y = y.to(device=device, dtype=torch.long)\n",
    "            y_pred,_ = model(x)\n",
    "            y_val = y.reshape(-1,1)\n",
    "            y_pred = y_pred.data.cpu().numpy()\n",
    "            \n",
    "            mAP = 100 * mean_ap_3(y_val,y_pred,1)\n",
    "            mAP3 = 100 * mean_ap_3(y_val,y_pred,3)\n",
    "            meanAP.append(mAP)\n",
    "            meanAP3.append(mAP3)\n",
    "            if i > 100:\n",
    "                break\n",
    "        \n",
    "        m1 = np.mean(meanAP)\n",
    "        m3 = np.mean(meanAP3)\n",
    "        \n",
    "\n",
    "        if (m3 > QDtrain[\"mAP3\"] + 1) and (m3 > 20):\n",
    "            if os.path.exists(QDtrain[\"file\"]):\n",
    "                os.remove(QDtrain[\"file\"])\n",
    "            QDtrain[\"file\"] = str(\"model\" + QDtrain[\"prefix\"] + str(m3))\n",
    "            torch.save(model.state_dict(),QDtrain[\"file\"])\n",
    "            QDtrain[\"mAP3\"] = m3\n",
    "            QDtrain[\"mAP\"] = m1\n",
    "        print('Got correct (%.2f,%.2f)' % (m1,m3 ))\n",
    "        \n",
    "        \n",
    "def train(model, optimizer, epochs,args):\n",
    "    \"\"\"\n",
    "    Train a model on quickdrawing.\n",
    "    \n",
    "    Inputs:\n",
    "    - model: A PyTorch Module giving the model to train.\n",
    "    - optimizer: An Optimizer object we will use to train the model\n",
    "    - epochs: A Python integer giving the number of epochs to train for\n",
    "    - args: argumetns for learning rate\n",
    "    \n",
    "    Returns: Nothing, but prints model accuracies during training.\n",
    "    \"\"\"\n",
    "\n",
    "    model = model.to(device=device)  # move the model parameters to CPU/GPU\n",
    "    loader_val = QD.QDloadStrokeData(val = True)\n",
    "    loader_val = DataLoader(dataset=loader_val, batch_size=256,shuffle=False)\n",
    "    \n",
    "    # We try to aggregate the several batches together \n",
    "    # so that we could have a big batchsize to fill in GPU.\n",
    "    # real_batch size = aggregated_batches * batch_size\n",
    "    aggregated_batches = 1\n",
    "    \n",
    "    for e in range(epochs):\n",
    "\n",
    "        train_map1 = AverageMeter()\n",
    "        train_map3 = AverageMeter()\n",
    "        \n",
    "        #Learning rate decay\n",
    "        adjust_learning_rate(optimizer, e, args)\n",
    "        \n",
    "        # We split the whole train dataset into 100 segments.\n",
    "        for i in range(100):\n",
    "            t1 = time.time()\n",
    "            total_loss = 0\n",
    "            train_dataset = QD.QDloadStrokeData(no=i,val = False,transforms = trans)          \n",
    "            train_loader = DataLoader(dataset=train_dataset, batch_size=256,shuffle=False)\n",
    "            for t, (x,stroke, y) in enumerate(train_loader):\n",
    "                model.train()  \n",
    "                x = x.to(device=device, dtype=dtype)  \n",
    "                y = y.to(device=device, dtype=torch.long)\n",
    "\n",
    "                #add the center feature returned from resnet \n",
    "                scores,cf_pred = model(x)\n",
    "                \n",
    "                #Caculate entropy loss\n",
    "                entropy_loss = F.cross_entropy(scores, y)\n",
    "                \n",
    "                #Caculate the center loss \n",
    "                center_loss = F.mse_loss(cf_pred,cf_class[y])\n",
    "                \n",
    "                loss = entropy_loss + alpha * center_loss\n",
    "                \n",
    "                total_loss += loss\n",
    "                #Calculate train accuracy\n",
    "                y_pred = scores.data.cpu().numpy()\n",
    "                y_val = y.reshape(-1,1)\n",
    "                \n",
    "                mAP = 100 * mean_ap_3(y_val,y_pred,1)\n",
    "                mAP3 = 100 * mean_ap_3(y_val,y_pred,3)\n",
    "             \n",
    "                train_map1.update(mAP,x.size(0))\n",
    "                train_map3.update(mAP3,x.size(0))         \n",
    "                                  \n",
    "                if t % aggregated_batches == 0:                    \n",
    "                    avg_loss = total_loss / aggregated_batches\n",
    "\n",
    "                    optimizer.zero_grad()\n",
    "                    avg_loss.backward()\n",
    "                    optimizer.step()\n",
    "                    total_loss = 0\n",
    "\n",
    "                    t2 = time.time()\n",
    "\n",
    "                    if t % (print_every) == 0:\n",
    "                        print('Epoch %d,Iteration %d,loss = %.4f,time %.4f,train accuracy(%.2f,%.2f)' % \n",
    "                              (e,t, avg_loss.item(),t2-t1,train_map1.avg,train_map3.avg))\n",
    "                        check_accuracy(loader_val, model)\n",
    "                        t1 = time.time()\n",
    "                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model = RN.resnet50(num_classes=40)\n",
    "optimizer = optim.Adam(cnn_model.parameters(),lr = args['learning_rate'])\n",
    "QDtrain = {\"mAP\":0,\"mAP3\":0,\"file\":\"\",\"prefix\":\"resnet50\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train(cnn_model,optimizer, epochs=5,args=args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. batch size = 64. count =  340 * 10240.\n",
    "   Iteration 29400, loss = 0.5610\n",
    "   Got 64 correct (80.22,85.62)\n",
    "2. batch size =128 count = 340 *10240 * 2\n",
    "    Iteration 37800, loss = 0.9535\n",
    "    Got 128 correct (77.65,83.64)\n",
    "3. batch size =128 count = 340 *10240 * 2 \n",
    "    train on 28 * 28 drawing transfered from stroke\n",
    "    Iteration 45900, loss = 0.9149\n",
    "    Got correct (57.55,65.98)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following codes comes from cs231N.\n",
    "from average_precision import mapk\n",
    "def mean_ap_torch(y_val,y_pred_score,k):\n",
    "    y_pred = [torch.sort(c,descending=True)[::-1][1][:k] for c in y_pred_score]\n",
    "    return mapk(y_val,y_pred,k)\n",
    "\n",
    "def mean_ap_3(y_val,y_pred_score,k):\n",
    "    y_pred = [np.argsort(c)[::-1][:k] for c in y_pred_score]\n",
    "    return mapk(y_val,y_pred,k)\n",
    "\n",
    "def check_accuracy(loader, model):\n",
    "    \n",
    "    model.eval()  # set model to evaluation mode\n",
    "    \n",
    "    meanAP = []\n",
    "    meanAP3 = []\n",
    "    with torch.no_grad():\n",
    "        for i ,(_,x, y) in enumerate(loader):\n",
    "            x = x.to(device=device, dtype=dtype)  # move to device, e.g. GPU\n",
    "            y = y.to(device=device, dtype=torch.long)\n",
    "            y_pred,_ = model(x,None)\n",
    "            y_val = y.reshape(-1,1)\n",
    "            y_pred = y_pred.data.cpu().numpy()\n",
    "            \n",
    "            mAP = 100 * mean_ap_3(y_val,y_pred,1)\n",
    "            mAP3 = 100 * mean_ap_3(y_val,y_pred,3)\n",
    "            meanAP.append(mAP)\n",
    "            meanAP3.append(mAP3)\n",
    "            if i > 100:\n",
    "                break\n",
    "        \n",
    "        m1 = np.mean(meanAP)\n",
    "        m3 = np.mean(meanAP3)\n",
    "        \n",
    "\n",
    "        if (m3 > QDtrain[\"mAP3\"] + 1) and (m3 > 20):\n",
    "            if os.path.exists(QDtrain[\"file\"]):\n",
    "                os.remove(QDtrain[\"file\"])\n",
    "            QDtrain[\"file\"] = str(\"model\" + QDtrain[\"prefix\"] + str(m3))\n",
    "            torch.save(model.state_dict(),QDtrain[\"file\"])\n",
    "            QDtrain[\"mAP3\"] = m3\n",
    "            QDtrain[\"mAP\"] = m1\n",
    "        print('Got correct (%.2f,%.2f)' % (m1,m3 ))\n",
    "        \n",
    "        \n",
    "def train(model, optimizer, epochs,args):\n",
    "    \"\"\"\n",
    "    Train a model on quickdrawing.\n",
    "    \n",
    "    Inputs:\n",
    "    - model: A PyTorch Module giving the model to train.\n",
    "    - optimizer: An Optimizer object we will use to train the model\n",
    "    - epochs: A Python integer giving the number of epochs to train for\n",
    "    - args: argumetns for learning rate\n",
    "    \n",
    "    Returns: Nothing, but prints model accuracies during training.\n",
    "    \"\"\"\n",
    "\n",
    "    model = model.to(device=device)  # move the model parameters to CPU/GPU\n",
    "    loader_val = QD.QDloadStrokeData(val = True)\n",
    "    loader_val = DataLoader(dataset=loader_val, batch_size=512,shuffle=False)\n",
    "    \n",
    "    # We try to aggregate the several batches together \n",
    "    # so that we could have a big batchsize to fill in GPU.\n",
    "    # real_batch size = aggregated_batches * batch_size\n",
    "    aggregated_batches = 1\n",
    "    \n",
    "    for e in range(epochs):\n",
    "\n",
    "        train_map1 = AverageMeter()\n",
    "        train_map3 = AverageMeter()\n",
    "        \n",
    "        #Learning rate decay\n",
    "        adjust_learning_rate(optimizer, e, args)\n",
    "        \n",
    "        # We split the whole train dataset into 100 segments.\n",
    "        for i in range(100):\n",
    "            t1 = time.time()\n",
    "            total_loss = 0\n",
    "            train_dataset = QD.QDloadStrokeData(no=i,val = False,transforms = trans)          \n",
    "            train_loader = DataLoader(dataset=train_dataset, batch_size=512,shuffle=False)\n",
    "            for t, (_, x, y) in enumerate(train_loader):\n",
    "                model.train()  \n",
    "                x = x.to(device=device, dtype=dtype)  \n",
    "                y = y.to(device=device, dtype=torch.long)\n",
    "                \n",
    "                #add the center feature returned from resnet \n",
    "                scores,_ = model(x,None)\n",
    "                #Caculate entropy loss\n",
    "                entropy_loss = F.cross_entropy(scores, y)\n",
    "                \n",
    "                total_loss += entropy_loss\n",
    "                #Calculate train accuracy\n",
    "                y_pred = scores.data.cpu().numpy()\n",
    "                y_val = y.reshape(-1,1)\n",
    "                \n",
    "                mAP = 100 * mean_ap_3(y_val,y_pred,1)\n",
    "                mAP3 = 100 * mean_ap_3(y_val,y_pred,3)\n",
    "             \n",
    "                train_map1.update(mAP,x.size(0))\n",
    "                train_map3.update(mAP3,x.size(0))         \n",
    "                                  \n",
    "                if t % aggregated_batches == 0:                    \n",
    "                    avg_loss = total_loss / aggregated_batches\n",
    "\n",
    "                    optimizer.zero_grad()\n",
    "                    avg_loss.backward()\n",
    "                    optimizer.step()\n",
    "                    total_loss = 0\n",
    "\n",
    "                    t2 = time.time()\n",
    "\n",
    "                    if t % (print_every) == 0:\n",
    "                        print('Epoch %d,Iteration %d,loss = %.4f,time %.4f,train accuracy(%.2f,%.2f)' % \n",
    "                              (e,t, avg_loss.item(),t2-t1,train_map1.avg,train_map3.avg))\n",
    "                        check_accuracy(loader_val, model)\n",
    "                        t1 = time.time()\n",
    "                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No = 0 and total number of items 20480\n",
      "No = 0 and total number of items 42546\n",
      "Epoch 0,Iteration 0,loss = 3.6896,time 17.9304,train accuracy(4.49,6.48)\n",
      "Got correct (7.69,11.74)\n",
      "Epoch 0,Iteration 75,loss = 2.2674,time 16.7262,train accuracy(27.20,36.83)\n",
      "Got correct (39.63,50.39)\n",
      "No = 1 and total number of items 42279\n",
      "Epoch 0,Iteration 0,loss = 2.1636,time 17.8066,train accuracy(28.39,38.13)\n",
      "Got correct (39.11,50.03)\n",
      "Epoch 0,Iteration 75,loss = 1.8297,time 16.7854,train accuracy(35.23,45.60)\n",
      "Got correct (48.01,59.15)\n",
      "No = 2 and total number of items 42425\n",
      "Epoch 0,Iteration 0,loss = 1.8685,time 18.7318,train accuracy(35.73,46.16)\n",
      "Got correct (48.05,59.14)\n",
      "Epoch 0,Iteration 75,loss = 1.5211,time 16.9511,train accuracy(40.15,50.70)\n"
     ]
    }
   ],
   "source": [
    "QDtrain = {\"mAP\":0,\"mAP3\":0,\"file\":\"\",\"prefix\":\"rnn\"}\n",
    "args = {\"learning_rate\" : 3e-4}\n",
    "rnn_model = SketchRNN(3, 256, 40,dropout=0.1)\n",
    "optimizer = optim.Adam(rnn_model.parameters(),lr = args['learning_rate'])\n",
    "train(rnn_model,optimizer, epochs=5,args=args)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Super Sketch Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Super Sketch Network links a RNN and CNN together with an attention layer in the last layer.\n",
    "class SSN(nn.Module):\n",
    "    \n",
    "    def __init__(self, cnn_model_name,rnn_model_name, d_frozen = False,num_classes=40):\n",
    "        super(SSN, self).__init__()\n",
    "        \n",
    "        self.cnn = RN.resnet50(num_classes=num_classes)\n",
    "        self.rnn = SketchRNN(3, 256, num_classes,dropout=0.1)\n",
    "        \n",
    "        self.attention = nn.Parameter(torch.FloatTensor(num_classes, 1))\n",
    "        torch.nn.init.xavier_normal_(self.attention)\n",
    "        \n",
    "        if os.path.exists(cnn_model_name):\n",
    "            self.cnn.load_state_dict(torch.load(cnn_model_name, map_location=lambda storage, loc: storage))\n",
    "\n",
    "        if os.path.exists(rnn_model_name):\n",
    "            self.rnn.load_state_dict(torch.load(rnn_model_name, map_location=lambda storage, loc: storage))\n",
    "            \n",
    "        if d_frozen:\n",
    "            for param in self.cnn.parameters():\n",
    "                param.requires_grad = False\n",
    "            for param in self.rnn.parameters():\n",
    "                param.requires_grad = False\n",
    "                \n",
    "        \n",
    "    def forward(self, images,strokes):\n",
    "        cnn_output,_ = self.cnn(images)\n",
    "        rnn_output,_ = self.rnn(strokes,None)\n",
    "        \n",
    "        #Attention Layer linking RNN and CNN together.\n",
    "        output = torch.stack([cnn_output,rnn_output],dim = 1)\n",
    "        att_score = torch.matmul(output, self.attention).squeeze()\n",
    "        att_score = F.softmax(att_score,dim = 1).view(output.size(0), output.size(1), 1)\n",
    "        score = output * att_score\n",
    "\n",
    "        score = torch.sum(score, dim=1)\n",
    "        \n",
    "        return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following codes comes from cs231N.\n",
    "from average_precision import mapk\n",
    "def mean_ap_torch(y_val,y_pred_score,k):\n",
    "    y_pred = [torch.sort(c,descending=True)[::-1][1][:k] for c in y_pred_score]\n",
    "    return mapk(y_val,y_pred,k)\n",
    "\n",
    "def mean_ap_3(y_val,y_pred_score,k):\n",
    "    y_pred = [np.argsort(c)[::-1][:k] for c in y_pred_score]\n",
    "    return mapk(y_val,y_pred,k)\n",
    "\n",
    "def check_accuracy(loader, model):\n",
    "    \n",
    "    model.eval()  # set model to evaluation mode\n",
    "    \n",
    "    meanAP = []\n",
    "    meanAP3 = []\n",
    "    with torch.no_grad():\n",
    "        for i ,(img,stroke, y) in enumerate(loader):\n",
    "            img = img.to(device=device, dtype=dtype)\n",
    "            stroke = stroke.to(device=device, dtype=dtype)\n",
    "            y = y.to(device=device, dtype=torch.long)\n",
    "            y_pred = model(img,stroke)\n",
    "            y_val = y.reshape(-1,1)\n",
    "            y_pred = y_pred.data.cpu().numpy()\n",
    "            \n",
    "            mAP = 100 * mean_ap_3(y_val,y_pred,1)\n",
    "            mAP3 = 100 * mean_ap_3(y_val,y_pred,3)\n",
    "            meanAP.append(mAP)\n",
    "            meanAP3.append(mAP3)\n",
    "            if i > 100:\n",
    "                break\n",
    "        \n",
    "        m1 = np.mean(meanAP)\n",
    "        m3 = np.mean(meanAP3)\n",
    "        \n",
    "\n",
    "        if (m3 > QDtrain[\"mAP3\"] + 1) and (m3 > 20):\n",
    "            if os.path.exists(QDtrain[\"file\"]):\n",
    "                os.remove(QDtrain[\"file\"])\n",
    "            QDtrain[\"file\"] = str(\"model\" + QDtrain[\"prefix\"] + str(m3))\n",
    "            torch.save(model.state_dict(),QDtrain[\"file\"])\n",
    "            QDtrain[\"mAP3\"] = m3\n",
    "            QDtrain[\"mAP\"] = m1\n",
    "        print('Got correct (%.2f,%.2f)' % (m1,m3 ))\n",
    "        \n",
    "        \n",
    "def train(model, optimizer, epochs,args):\n",
    "    \"\"\"\n",
    "    Train a model on quickdrawing.\n",
    "    \n",
    "    Inputs:\n",
    "    - model: A PyTorch Module giving the model to train.\n",
    "    - optimizer: An Optimizer object we will use to train the model\n",
    "    - epochs: A Python integer giving the number of epochs to train for\n",
    "    - args: argumetns for learning rate\n",
    "    \n",
    "    Returns: Nothing, but prints model accuracies during training.\n",
    "    \"\"\"\n",
    "\n",
    "    model = model.to(device=device)  # move the model parameters to CPU/GPU\n",
    "    loader_val = QD.QDloadStrokeData(val = True)\n",
    "    loader_val = DataLoader(dataset=loader_val, batch_size=256,shuffle=False)\n",
    "    \n",
    "    # We try to aggregate the several batches together \n",
    "    # so that we could have a big batchsize to fill in GPU.\n",
    "    # real_batch size = aggregated_batches * batch_size\n",
    "    aggregated_batches = 1\n",
    "    \n",
    "    for e in range(epochs):\n",
    "\n",
    "        train_map1 = AverageMeter()\n",
    "        train_map3 = AverageMeter()\n",
    "        \n",
    "        #Learning rate decay\n",
    "        adjust_learning_rate(optimizer, e, args)\n",
    "        \n",
    "        # We split the whole train dataset into 100 segments.\n",
    "        for i in range(100):\n",
    "            t1 = time.time()\n",
    "            total_loss = 0\n",
    "            train_dataset = QD.QDloadStrokeData(no=i,val = False,transforms = trans)          \n",
    "            train_loader = DataLoader(dataset=train_dataset, batch_size=256,shuffle=False)\n",
    "            for t, (img, stroke, y) in enumerate(train_loader):\n",
    "                model.train()  \n",
    "                img = img.to(device=device, dtype=dtype)  \n",
    "                stroke = stroke.to(device=device, dtype=dtype)\n",
    "                y = y.to(device=device, dtype=torch.long)\n",
    "                \n",
    "                #add the center feature returned from resnet \n",
    "                scores = model(img,stroke)\n",
    "                \n",
    "                #Caculate entropy loss\n",
    "                entropy_loss = F.cross_entropy(scores, y)\n",
    "                total_loss += entropy_loss\n",
    "                \n",
    "                #Calculate train accuracy\n",
    "                y_pred = scores.data.cpu().numpy()\n",
    "                y_val = y.reshape(-1,1)\n",
    "                \n",
    "                mAP = 100 * mean_ap_3(y_val,y_pred,1)\n",
    "                mAP3 = 100 * mean_ap_3(y_val,y_pred,3)\n",
    "             \n",
    "                train_map1.update(mAP,img.size(0))\n",
    "                train_map3.update(mAP3,img.size(0))         \n",
    "                                  \n",
    "                if t % aggregated_batches == 0:                    \n",
    "                    avg_loss = total_loss / aggregated_batches\n",
    "\n",
    "                    optimizer.zero_grad()\n",
    "                    avg_loss.backward()\n",
    "                    optimizer.step()\n",
    "                    total_loss = 0\n",
    "\n",
    "                    t2 = time.time()\n",
    "\n",
    "                    if t % (print_every) == 0:\n",
    "                        print('Epoch %d,Iteration %d,loss = %.4f,time %.4f,train accuracy(%.2f,%.2f)' % \n",
    "                              (e,t, avg_loss.item(),t2-t1,train_map1.avg,train_map3.avg))\n",
    "                        check_accuracy(loader_val, model)\n",
    "                        t1 = time.time()\n",
    "                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "QDtrain = {\"mAP\":0,\"mAP3\":0,\"file\":\"\",\"prefix\":\"SSN\"}\n",
    "args = {\"learning_rate\" : 3e-4}\n",
    "ssn_model = SSN(\"modelresnet5088.17546\",\"model\")\n",
    "optimizer = optim.Adam(ssn_model.parameters(),lr = args['learning_rate'])\n",
    "train(ssn_model,optimizer, epochs=5,args=args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run test samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ssn_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(),\"ssn_model.91.14\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_test(test_data, model):\n",
    "    model.eval()  \n",
    "    with torch.no_grad():\n",
    "        meanAP = []\n",
    "        meanAP3 = []\n",
    "        center_feature = []\n",
    "        \n",
    "        for i ,(img,stroke,y) in enumerate(test_data):\n",
    "            img = img.to(device=device, dtype=dtype)\n",
    "            stroke = stroke.to(device=device, dtype=dtype)\n",
    "            y = y.to(device=device, dtype=torch.long)\n",
    "            y_pred,feature_pred = model(x)\n",
    "            y_val = y.reshape(-1,1)\n",
    "            y_pred = y_pred.data.cpu().numpy()\n",
    "            feature_pred = feature_pred.data.cpu().numpy()\n",
    "            \n",
    "            mAP = 100 * mean_ap_3(y_val,y_pred,1)\n",
    "            mAP3 = 100 * mean_ap_3(y_val,y_pred,3)\n",
    "            meanAP.append(mAP)\n",
    "            meanAP3.append(mAP3)\n",
    "\n",
    "            center_feature.extend(feature_pred)\n",
    "            \n",
    "        m1 = np.mean(meanAP)\n",
    "        m3 = np.mean(meanAP3)\n",
    "        print(len(center_feature),center_feature[0].shape)\n",
    "        return (m1,m3,center_feature,y_pred,y_val)\n",
    "\n",
    "model = model.to(device=device)\n",
    "checkpoint = torch.load(\"ssn_model.91.14\")\n",
    "model.load_state_dict(checkpoint)\n",
    "\n",
    "class_name = QD.qd_names\n",
    "\n",
    "class_accuracy = []\n",
    "center_feature = []\n",
    "y_list = []\n",
    "\n",
    "val_accuracy_map1 = AverageMeter()\n",
    "val_accuracy_map3 = AverageMeter()\n",
    "\n",
    "for i,name in enumerate(tqdm(class_name)):\n",
    "    t1 = time.time()\n",
    "    batch_size = 128\n",
    "    data_file = os.path.join(\"./train\",name+\".csv\")\n",
    "    test_data = QD.QDloadStrokeData(data_file = data_file)\n",
    "    test_loader = DataLoader(dataset=test_data, batch_size=batch_size, num_workers=2, shuffle=False)\n",
    "\n",
    "    m1,m3,feature_list,y_pred,y = evaluate_test(test_loader,model)\n",
    "    \n",
    "    feature_list = np.array(feature_list)\n",
    "    print(feature_list.shape)\n",
    "    \n",
    "    #feature_list is N * 2048\n",
    "    \n",
    "    center_feature.append(np.mean(feature_list,axis = 0))\n",
    "\n",
    "    class_accuracy.append((name,str(m1),str(m3)))\n",
    "    y_list.append((y_pred))\n",
    "    \n",
    "    val_accuracy_map1.update(m1,feature_list[0])\n",
    "    val_accuracy_map3.update(m3,feature_list[0])\n",
    "    \n",
    "    print(name,str(m1),str(m3))\n",
    "    t2 = time.time()\n",
    "    print(\"Time:\",t2-t1)\n",
    "    \n",
    "with open('class_accuracy.csv',\"w+\") as fp:\n",
    "    writer = csv.writer(fp, delimiter=',')\n",
    "    writer.writerow([\"class\", \"meanAP1\", \"meanAP3\"])  # write header\n",
    "    writer.writerows(class_accuracy)\n",
    "\n",
    "print(\"The average accuracy %.4f %.4f\",val_accuracy_map1.avg,val_accuracy_map3.avg)\n",
    "np.save(\"y_test_list\",y_list)\n",
    "\n",
    "np.save(\"center_feature\",center_feature)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) 96*96, resnet50, epoch 10, GSD. 75.2%\n",
    "2) 96*96, resnet50, epoch 10, GSD  79.9% model_parametertensor(91.6667)\n",
    "3) 96*96, resnet50, epoch 10, Adam model_resnet_92.317_90\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* convert simplified test dataset to pixel drawsing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the accuracy based on the class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create test_simplified.\n",
    "load compressed(96*96) 1.968482494354248\n",
    "load non compressed(96*96)  0.31299567222595215\n",
    "load non compressed(28*28) 0.04715704917907715\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10,11):\n",
    "    data = QD.QDcreateData()\n",
    "    data.create(start=i*3000,dir_name=\"../cs230/pic96\")\n",
    "    del data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
