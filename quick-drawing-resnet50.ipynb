{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quick Drawing is a kaggle challenge for classifying the sketch pictures. The total number of category is 340 and \n",
    "there are 50M pictures in the dataset. Each catogory has 25,000 pictures. The difficulty is the drawing might be \n",
    "incomplete or the drawing does not match the label. We are trying to develop a CNN to solve the issue.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the challenge, there are 4 kinds of dataset. \n",
    "\n",
    "    - Raw data (.ndjson)\n",
    "    - Simplified drawings (.ndjson)\n",
    "    - Binary data (.bin)\n",
    "    - Bitmap data (.npy)\n",
    "Raw data and Simplified drawings are provided in a vector information of strokes. Bitmap data is rendered into \n",
    "28 * 28 grayscale bitmap in the numpy format.  \n",
    "\n",
    "Maybe we could consider the raw data to improve the performance since it inlcudes the sequence information.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import time\n",
    "import torch\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import sampler\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as T\n",
    "import numpy as np\n",
    "from torch.utils import data\n",
    "import QDdata as QD\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from torch.utils.data import DataLoader\n",
    "import resnet as RN\n",
    "from torchvision import transforms\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device: cuda\n"
     ]
    }
   ],
   "source": [
    "USE_GPU = True\n",
    "\n",
    "dtype = torch.float32 # we will be using float throughout this tutorial\n",
    "\n",
    "if USE_GPU and torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "# Constant to control how frequently we print train loss\n",
    "print_every = 75\n",
    "\n",
    "print('using device:', device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans = transforms.Compose([transforms.RandomHorizontalFlip(0.5), transforms.ToTensor()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Center Feature Per Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.01\n",
    "cf_class = torch.from_numpy(np.load(\"center_feature.npy\"))\n",
    "cf_class = cf_class.to(device=device, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\"learning_rate\" : 3e-3}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following code comes from https://github.com/pytorch/examples/blob/master/imagenet/main.py\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "def adjust_learning_rate(optimizer, epoch, args):\n",
    "    \"\"\"Sets the learning rate to the initial LR decayed by 10 every 30 epochs\"\"\"\n",
    "    lr = args['learning_rate'] * (0.5 ** epoch )\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr\n",
    "\n",
    "def accuracy(output, target, topk=(1,)):\n",
    "    \"\"\"Computes the accuracy over the k top predictions for the specified values of k\"\"\"\n",
    "    with torch.no_grad():\n",
    "        maxk = max(topk)\n",
    "        batch_size = target.size(0)\n",
    "\n",
    "        _, pred = output.topk(maxk, 1, True, True)\n",
    "        pred = pred.t()\n",
    "        correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "        res = []\n",
    "        for k in topk:\n",
    "            correct_k = correct[:k].view(-1).float().sum(0, keepdim=True)\n",
    "            res.append(correct_k.mul_(100.0 / batch_size))\n",
    "        return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resnet50 96X96"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following codes comes from cs231N.\n",
    "from average_precision import mapk\n",
    "def mean_ap_torch(y_val,y_pred_score,k):\n",
    "    y_pred = [torch.sort(c,descending=True)[::-1][1][:k] for c in y_pred_score]\n",
    "    return mapk(y_val,y_pred,k)\n",
    "\n",
    "def mean_ap_3(y_val,y_pred_score,k):\n",
    "    y_pred = [np.argsort(c)[::-1][:k] for c in y_pred_score]\n",
    "    return mapk(y_val,y_pred,k)\n",
    "\n",
    "def check_accuracy(loader, model):\n",
    "    \n",
    "    model.eval()  # set model to evaluation mode\n",
    "    \n",
    "    meanAP = []\n",
    "    meanAP3 = []\n",
    "    with torch.no_grad():\n",
    "        for i ,(x, y) in enumerate(loader):\n",
    "            x = x.to(device=device, dtype=dtype)  # move to device, e.g. GPU\n",
    "            y = y.to(device=device, dtype=torch.long)\n",
    "            y_pred,_ = model(x)\n",
    "            y_val = y.reshape(-1,1)\n",
    "            y_pred = y_pred.data.cpu().numpy()\n",
    "            \n",
    "            mAP = 100 * mean_ap_3(y_val,y_pred,1)\n",
    "            mAP3 = 100 * mean_ap_3(y_val,y_pred,3)\n",
    "            meanAP.append(mAP)\n",
    "            meanAP3.append(mAP3)\n",
    "            if i > 100:\n",
    "                break\n",
    "        \n",
    "        m1 = np.mean(meanAP)\n",
    "        m3 = np.mean(meanAP3)\n",
    "        \n",
    "\n",
    "        if (m3 > QDtrain[\"mAP3\"] + 1) and (m3 > 20):\n",
    "            if os.path.exists(QDtrain[\"file\"]):\n",
    "                os.remove(QDtrain[\"file\"])\n",
    "            QDtrain[\"file\"] = str(\"model\" + QDtrain[\"prefix\"] + str(m3))\n",
    "            torch.save(model.state_dict(),QDtrain[\"file\"])\n",
    "            QDtrain[\"mAP3\"] = m3\n",
    "            QDtrain[\"mAP\"] = m1\n",
    "        print('Got correct (%.2f,%.2f)' % (m1,m3 ))\n",
    "        \n",
    "        \n",
    "def train(model, optimizer, epochs,args):\n",
    "    \"\"\"\n",
    "    Train a model on quickdrawing.\n",
    "    \n",
    "    Inputs:\n",
    "    - model: A PyTorch Module giving the model to train.\n",
    "    - optimizer: An Optimizer object we will use to train the model\n",
    "    - epochs: A Python integer giving the number of epochs to train for\n",
    "    - args: argumetns for learning rate\n",
    "    \n",
    "    Returns: Nothing, but prints model accuracies during training.\n",
    "    \"\"\"\n",
    "\n",
    "    model = model.to(device=device)  # move the model parameters to CPU/GPU\n",
    "    loader_val = QD.QDloadStrokeData(val = True)\n",
    "    loader_val = DataLoader(dataset=loader_val, batch_size=256,shuffle=False)\n",
    "    \n",
    "    # We try to aggregate the several batches together \n",
    "    # so that we could have a big batchsize to fill in GPU.\n",
    "    # real_batch size = aggregated_batches * batch_size\n",
    "    aggregated_batches = 1\n",
    "    \n",
    "    for e in range(epochs):\n",
    "\n",
    "        train_map1 = AverageMeter()\n",
    "        train_map3 = AverageMeter()\n",
    "        \n",
    "        #Learning rate decay\n",
    "        adjust_learning_rate(optimizer, e, args)\n",
    "        \n",
    "        # We split the whole train dataset into 100 segments.\n",
    "        for i in range(100):\n",
    "            t1 = time.time()\n",
    "            total_loss = 0\n",
    "            train_dataset = QD.QDloadStrokeData(no=i,val = False,transforms = trans)          \n",
    "            train_loader = DataLoader(dataset=train_dataset, batch_size=512,shuffle=False)\n",
    "            for t, (x, y) in enumerate(train_loader):\n",
    "                model.train()  # put model to training mode\n",
    "                x = x.to(device=device, dtype=dtype)  # move to device, e.g. GPU\n",
    "                y = y.to(device=device, dtype=torch.long)\n",
    "\n",
    "                #add the center feature returned from resnet \n",
    "                scores,cf_pred = model(x)\n",
    "                \n",
    "                #Caculate entropy loss\n",
    "                entropy_loss = F.cross_entropy(scores, y)\n",
    "                \n",
    "                #Caculate the center loss \n",
    "                center_loss = F.mse_loss(cf_pred,cf_class[y])\n",
    "                \n",
    "                loss = entropy_loss + alpha * center_loss\n",
    "                \n",
    "                total_loss += loss\n",
    "                #Calculate train accuracy\n",
    "                y_pred = scores.data.cpu().numpy()\n",
    "                y_val = y.reshape(-1,1)\n",
    "                \n",
    "                mAP = 100 * mean_ap_3(y_val,y_pred,1)\n",
    "                mAP3 = 100 * mean_ap_3(y_val,y_pred,3)\n",
    "             \n",
    "                train_map1.update(mAP,x.size(0))\n",
    "                train_map3.update(mAP3,x.size(0))         \n",
    "                #acc1,acc3 = accuracy(scores, y, topk=(1, 3))\n",
    "                #train_map1.update(acc1,x.size(0))\n",
    "                #train_map3.update(acc3,x.size(0))\n",
    "                                  \n",
    "                if t % aggregated_batches == 0:                    \n",
    "                    avg_loss = total_loss / aggregated_batches\n",
    "\n",
    "                    optimizer.zero_grad()\n",
    "                    avg_loss.backward()\n",
    "                    optimizer.step()\n",
    "                    total_loss = 0\n",
    "\n",
    "                    t2 = time.time()\n",
    "\n",
    "                    if t % (print_every) == 0:\n",
    "                        print('Epoch %d,Iteration %d,loss = %.4f,time %.4f,train accuracy(%.2f,%.2f)' % \n",
    "                              (e,t, avg_loss.item(),t2-t1,train_map1.avg,train_map3.avg))\n",
    "                        check_accuracy(loader_val, model)\n",
    "                        t1 = time.time()\n",
    "                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RN.resnet50(num_classes=40)\n",
    "optimizer = optim.Adam(model.parameters(),lr = args['learning_rate'])\n",
    "QDtrain = {\"mAP\":0,\"mAP3\":0,\"file\":\"\",\"prefix\":\"resnet50\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No = 0 and total number of items 20480\n",
      "No = 0 and total number of items 42546\n",
      "Epoch 0,Iteration 0,loss = 3.9462,time 6.1264,train accuracy(3.12,5.11)\n",
      "Got correct (2.50,4.58)\n",
      "Epoch 0,Iteration 75,loss = 2.7906,time 51.8443,train accuracy(8.06,12.90)\n",
      "Got correct (19.00,28.26)\n",
      "No = 1 and total number of items 42279\n",
      "Epoch 0,Iteration 0,loss = 2.6064,time 6.0869,train accuracy(9.57,14.97)\n",
      "Got correct (21.71,32.86)\n",
      "Epoch 0,Iteration 75,loss = 1.6249,time 52.5151,train accuracy(24.69,33.21)\n",
      "Got correct (49.34,60.86)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-2893efb6c10b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-7-bb7091618058>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, optimizer, epochs, args)\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0mt1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m             \u001b[0mtotal_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m             \u001b[0mtrain_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mQD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mQDloadStrokeData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mno\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtransforms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrans\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m             \u001b[0mtrain_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/kaggle/project/QDdata.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, no, data_file, val, image_size, transforms)\u001b[0m\n\u001b[1;32m    358\u001b[0m         \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m         \u001b[0mentropybag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbag\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrawing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_draw_cv2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 360\u001b[0;31m         \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mentropybag\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    361\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'y'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/dask/base.py\u001b[0m in \u001b[0;36mcompute\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0mdask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m         \"\"\"\n\u001b[0;32m--> 154\u001b[0;31m         \u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraverse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    155\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/dask/base.py\u001b[0m in \u001b[0;36mcompute\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    405\u001b[0m     \u001b[0mkeys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dask_keys__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m     \u001b[0mpostcomputes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dask_postcompute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 407\u001b[0;31m     \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdsk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mrepack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpostcomputes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/dask/multiprocessing.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(dsk, keys, num_workers, func_loads, func_dumps, optimize_graph, **kwargs)\u001b[0m\n\u001b[1;32m    175\u001b[0m                            \u001b[0mget_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_process_get_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdumps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloads\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m                            \u001b[0mpack_exception\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpack_exception\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 177\u001b[0;31m                            raise_exception=reraise, **kwargs)\n\u001b[0m\u001b[1;32m    178\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcleanup\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/dask/local.py\u001b[0m in \u001b[0;36mget_async\u001b[0;34m(apply_async, num_workers, dsk, result, cache, get_id, rerun_exceptions_locally, pack_exception, raise_exception, callbacks, dumps, loads, **kwargs)\u001b[0m\n\u001b[1;32m    510\u001b[0m             \u001b[0;31m# Main loop, wait on tasks to finish, insert new ones\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    511\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'waiting'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ready'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'running'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 512\u001b[0;31m                 \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres_info\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfailed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mqueue_get\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    513\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mfailed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    514\u001b[0m                     \u001b[0mexc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres_info\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/dask/local.py\u001b[0m in \u001b[0;36mqueue_get\u001b[0;34m(q)\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mqueue_get\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/queue.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    162\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m                 \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_qsize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_empty\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    165\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"'timeout' must be a non-negative number\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(model, optimizer, epochs=5,args=args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. batch size = 64. count =  340 * 10240.\n",
    "   Iteration 29400, loss = 0.5610\n",
    "   Got 64 correct (80.22,85.62)\n",
    "2. batch size =128 count = 340 *10240 * 2\n",
    "    Iteration 37800, loss = 0.9535\n",
    "    Got 128 correct (77.65,83.64)\n",
    "3. batch size =128 count = 340 *10240 * 2 \n",
    "    train on 28 * 28 drawing transfered from stroke\n",
    "    Iteration 45900, loss = 0.9149\n",
    "    Got correct (57.55,65.98)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "class SketchRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, dropout = 0.3 n_layers=1):\n",
    "        super(SketchRNN, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "        self.conv1d_1 = nn.Conv1d(input_size, 48, 5)\n",
    "        self.dropout_1 = nn.Dropout(0.3)\n",
    "        self.conv1d_2 = nn.Conv1d(48, 64, 5)\n",
    "        self.dropout_2 = nn.Dropout(0.3)\n",
    "        self.conv1d_3 = nn.Conv1d(64, 96, 3)\n",
    "        self.dropout_3 = nn.Dropout(0.3)\n",
    "        self.lstm_1 = nn.LSTM(96,hidden_size, n_layers, dropout,batch_first=True)\n",
    "        self.fc_mu = nn.Linear(hidden_size, output_size)\n",
    "        \n",
    "\n",
    "    def forward(self, inputs, hidden):\n",
    "        inputs = inputs.transpose(0, 1).transpose(1, 2)\n",
    "        #print(\"inputs\",type(inputs))\n",
    "        #print(\"inputs\",inputs.size())\n",
    "        output = self.conv1d_1(inputs)\n",
    "        #print(output.size())\n",
    "        output = self.dropout_1(output)\n",
    "        output = self.conv1d_2(output)\n",
    "        #print(output.size())\n",
    "        output = self.dropout_2(output)\n",
    "        output = self.conv1d_3(output)\n",
    "        #print(output.size())\n",
    "        output = self.dropout_3(output)\n",
    "        output = output.transpose(1, 2)\n",
    "        #output = output.transpose(1, 2).transpose(0, 1)\n",
    "        #print(\"output\",type(output))\n",
    "        output, (hidden,x) = self.lstm_1(output, hidden)\n",
    "        output_in_last_timestep=output[:,-1,:]\n",
    "        #print(\"output\",output.size())\n",
    "        #print(hidden.size())\n",
    "        #print(x.size())\n",
    "        #print(\"output_in_last_timestep\", output_in_last_timestep.size())\n",
    "        output = self.fc_mu(output_in_last_timestep)\n",
    "        #print(\"fc output\", output.size())\n",
    "        output = F.log_softmax(output, dim=1)\n",
    "        return output, hidden \n",
    "\n",
    "model = SketchRNN(3, 128, 340,drop=0.3).to(device)\n",
    "optimizer = optim.Adam(model.parameters(),weight_decay = 1e-5,lr=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run test samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(),\"center-loss93.93\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_test(test_data, model):\n",
    "    model.eval()  \n",
    "    with torch.no_grad():\n",
    "        meanAP = []\n",
    "        meanAP3 = []\n",
    "        center_feature = []\n",
    "        \n",
    "        for i ,(x,y) in enumerate(test_data):\n",
    "            x = x.to(device=device, dtype=dtype)  # move to device, e.g. GPU\n",
    "            y = y.to(device=device, dtype=torch.long)\n",
    "            y_pred,feature_pred = model(x)\n",
    "            y_val = y.reshape(-1,1)\n",
    "            y_pred = y_pred.data.cpu().numpy()\n",
    "            feature_pred = feature_pred.data.cpu().numpy()\n",
    "            \n",
    "            mAP = 100 * mean_ap_3(y_val,y_pred,1)\n",
    "            mAP3 = 100 * mean_ap_3(y_val,y_pred,3)\n",
    "            meanAP.append(mAP)\n",
    "            meanAP3.append(mAP3)\n",
    "\n",
    "            center_feature.extend(feature_pred)\n",
    "            \n",
    "        m1 = np.mean(meanAP)\n",
    "        m3 = np.mean(meanAP3)\n",
    "        print(len(center_feature),center_feature[0].shape)\n",
    "        return (m1,m3,center_feature)\n",
    "\n",
    "model = model.to(device=device)\n",
    "checkpoint = torch.load(\"modelresnet5093.680016\")\n",
    "model.load_state_dict(checkpoint)\n",
    "\n",
    "class_name = QD.qd_names\n",
    "\n",
    "class_accuracy = []\n",
    "\n",
    "center_feature = []\n",
    "\n",
    "val_accuracy_map1 = AverageMeter()\n",
    "val_accuracy_map3 = AverageMeter()\n",
    "\n",
    "for i,name in enumerate(tqdm(class_name)):\n",
    "    t1 = time.time()\n",
    "    batch_size = 128\n",
    "    data_file = os.path.join(\"./train\",name+\".csv\")\n",
    "    test_data = QD.QDloadStrokeData(data_file = data_file)\n",
    "    test_loader = DataLoader(dataset=test_data, batch_size=batch_size, num_workers=2, shuffle=False)\n",
    "\n",
    "    m1,m3,feature_list = evaluate_test(test_loader,model)\n",
    "    \n",
    "    feature_list = np.array(feature_list)\n",
    "    print(feature_list.shape)\n",
    "    \n",
    "    #feature_list is N * 2048\n",
    "    \n",
    "    center_feature.append(np.mean(feature_list,axis = 0))\n",
    "\n",
    "    class_accuracy.append((name,str(m1),str(m3)))\n",
    "    \n",
    "    val_accuracy_map1.update(m1,feature_list[0])\n",
    "    val_accuracy_map3.update(m3,feature_list[0])\n",
    "    \n",
    "    print(name,str(m1),str(m3))\n",
    "    t2 = time.time()\n",
    "    print(\"Time:\",t2-t1)\n",
    "    \n",
    "with open('class_accuracy.csv',\"w+\") as fp:\n",
    "    writer = csv.writer(fp, delimiter=',')\n",
    "    writer.writerow([\"class\", \"meanAP1\", \"meanAP3\"])  # write header\n",
    "    writer.writerows(class_accuracy)\n",
    "\n",
    "print(\"The average accuracy %.4f %.4f\",val_accuracy_map1.avg,val_accuracy_map3.avg)\n",
    "\n",
    "np.save(\"center_feature\",center_feature)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) 96*96, resnet50, epoch 10, GSD. 75.2%\n",
    "2) 96*96, resnet50, epoch 10, GSD  79.9% model_parametertensor(91.6667)\n",
    "3) 96*96, resnet50, epoch 10, Adam model_resnet_92.317_90\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* convert simplified test dataset to pixel drawsing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the accuracy based on the class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create test_simplified.\n",
    "load compressed(96*96) 1.968482494354248\n",
    "load non compressed(96*96)  0.31299567222595215\n",
    "load non compressed(28*28) 0.04715704917907715\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10,11):\n",
    "    data = QD.QDcreateData()\n",
    "    data.create(start=i*3000,dir_name=\"../cs230/pic96\")\n",
    "    del data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
