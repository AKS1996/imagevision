{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quick Drawing is a kaggle challenge for classifying the sketch pictures. The total number of category is 340 and \n",
    "there are 50M pictures in the dataset. Each catogory has 25,000 pictures. The difficulty is the drawing might be \n",
    "incomplete or the drawing does not match the label. We are trying to develop a CNN to solve the issue.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the challenge, there are 4 kinds of dataset. \n",
    "\n",
    "    - Raw data (.ndjson)\n",
    "    - Simplified drawings (.ndjson)\n",
    "    - Binary data (.bin)\n",
    "    - Bitmap data (.npy)\n",
    "Raw data and Simplified drawings are provided in a vector information of strokes. Bitmap data is rendered into \n",
    "28 * 28 grayscale bitmap in the numpy format.  \n",
    "\n",
    "Maybe we could consider the raw data to improve the performance since it inlcudes the sequence information.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import time\n",
    "import torch\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import sampler\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as T\n",
    "import numpy as np\n",
    "from torch.utils import data\n",
    "import QDdata as QD\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from torch.utils.data import DataLoader\n",
    "import resnet as RN\n",
    "from torchvision import transforms\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "USE_GPU = True\n",
    "\n",
    "dtype = torch.float32 # we will be using float throughout this tutorial\n",
    "\n",
    "if USE_GPU and torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "# Constant to control how frequently we print train loss\n",
    "print_every = 300\n",
    "\n",
    "print('using device:', device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans = transforms.Compose([transforms.RandomHorizontalFlip(0.5), transforms.ToTensor()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Center Feature Per Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.001\n",
    "cf_class = torch.from_numpy(np.load(\"center_feature_ssn.npy\"))\n",
    "cf_class = cf_class.to(device=device, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\"learning_rate\" : 5e-4, \"model\" : \"cnn\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following code comes from https://github.com/pytorch/examples/blob/master/imagenet/main.py\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "def adjust_learning_rate(optimizer, epoch, args):\n",
    "    \"\"\"Sets the learning rate to the initial LR decayed by 0.5 every epoch\"\"\"\n",
    "    lr = args['learning_rate'] * (0.5 ** epoch )\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr\n",
    "\n",
    "def accuracy(output, target, topk=(1,)):\n",
    "    \"\"\"Computes the accuracy over the k top predictions for the specified values of k\"\"\"\n",
    "    with torch.no_grad():\n",
    "        maxk = max(topk)\n",
    "        batch_size = target.size(0)\n",
    "\n",
    "        _, pred = output.topk(maxk, 1, True, True)\n",
    "        pred = pred.t()\n",
    "        correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "        res = []\n",
    "        for k in topk:\n",
    "            correct_k = correct[:k].view(-1).float().sum(0, keepdim=True)\n",
    "            res.append(correct_k.mul_(100.0 / batch_size))\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SketchRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, dropout = 0.1, n_layers=1):\n",
    "        super(SketchRNN, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "        self.conv1d_1 = nn.Conv1d(input_size, 48, 5)\n",
    "        self.dropout_1 = nn.Dropout(0.1)\n",
    "        self.conv1d_2 = nn.Conv1d(48, 64, 5)\n",
    "        self.dropout_2 = nn.Dropout(0.1)\n",
    "        self.conv1d_3 = nn.Conv1d(64, 96, 3)\n",
    "        self.dropout_3 = nn.Dropout(0.1)\n",
    "        self.lstm_1 = nn.LSTM(96,hidden_size, n_layers, dropout,batch_first=True,bidirectional=True)\n",
    "        self.fc_mu1 = nn.Linear(hidden_size*186*2, output_size)\n",
    "        #self.fc_mu2 = nn.Linear(128, output_size)\n",
    "\n",
    "    def forward(self, inputs, hidden):\n",
    "        inputs = inputs.transpose(1, 2)\n",
    "        \n",
    "        output = self.conv1d_1(inputs)\n",
    "        output = self.dropout_1(output)\n",
    "        output = self.conv1d_2(output)\n",
    "        output = self.dropout_2(output)\n",
    "        output = self.conv1d_3(output)\n",
    "        output = self.dropout_3(output)\n",
    "        output = output.transpose(1, 2)\n",
    "        \n",
    "        output, (hidden,x) = self.lstm_1(output, hidden)\n",
    "        \n",
    "        output = output.contiguous()\n",
    "        output = output.view(output.size(0),-1)\n",
    "        output_lstm = self.fc_mu1(output)\n",
    "        #output = self.fc_mu2(output_lstm)\n",
    "        output = F.log_softmax(output_lstm, dim=1)\n",
    "        return output, output_lstm "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resnet50 96X96"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### The following codes comes from cs231N.\n",
    "from average_precision import mapk\n",
    "def mean_ap_torch(y_val,y_pred_score,k):\n",
    "    y_pred = [torch.sort(c,descending=True)[::-1][1][:k] for c in y_pred_score]\n",
    "    return mapk(y_val,y_pred,k)\n",
    "\n",
    "def mean_ap_3(y_val,y_pred_score,k):\n",
    "    y_pred = [np.argsort(c)[::-1][:k] for c in y_pred_score]\n",
    "    return mapk(y_val,y_pred,k)\n",
    "\n",
    "def check_accuracy(loader, model):\n",
    "    \n",
    "    model.eval()  # set model to evaluation mode\n",
    "    \n",
    "    meanAP = []\n",
    "    meanAP3 = []\n",
    "    with torch.no_grad():\n",
    "        for i ,(x,stroke, y) in enumerate(loader):\n",
    "            x = x.to(device=device, dtype=dtype)  # move to device, e.g. GPU\n",
    "            y = y.to(device=device, dtype=torch.long)\n",
    "            y_pred,_ = model(x)\n",
    "            y_val = y.reshape(-1,1)\n",
    "            y_pred = y_pred.data.cpu().numpy()\n",
    "            \n",
    "            mAP = 100 * mean_ap_3(y_val,y_pred,1)\n",
    "            mAP3 = 100 * mean_ap_3(y_val,y_pred,3)\n",
    "            meanAP.append(mAP)\n",
    "            meanAP3.append(mAP3)\n",
    "            if i > 100:\n",
    "                break\n",
    "        \n",
    "        m1 = np.mean(meanAP)\n",
    "        m3 = np.mean(meanAP3)\n",
    "        \n",
    "\n",
    "        if (m3 > QDtrain[\"mAP3\"] + 1) and (m3 > 20):\n",
    "            if os.path.exists(QDtrain[\"file\"]):\n",
    "                os.remove(QDtrain[\"file\"])\n",
    "            QDtrain[\"file\"] = str(\"model\" + QDtrain[\"prefix\"] + str(m3))\n",
    "            torch.save(model.state_dict(),QDtrain[\"file\"])\n",
    "            QDtrain[\"mAP3\"] = m3\n",
    "            QDtrain[\"mAP\"] = m1\n",
    "        print('Got correct (%.2f,%.2f)' % (m1,m3 ))\n",
    "        \n",
    "        \n",
    "def train(model, optimizer, epochs,args):\n",
    "    \"\"\"\n",
    "    Train a model on quickdrawing.\n",
    "    \n",
    "    Inputs:\n",
    "    - model: A PyTorch Module giving the model to train.\n",
    "    - optimizer: An Optimizer object we will use to train the model\n",
    "    - epochs: A Python integer giving the number of epochs to train for\n",
    "    - args: argumetns for learning rate\n",
    "    \n",
    "    Returns: Nothing, but prints model accuracies during training.\n",
    "    \"\"\"\n",
    "\n",
    "    model = model.to(device=device)  # move the model parameters to CPU/GPU\n",
    "    loader_val = QD.QDloadStrokeData(val = True)\n",
    "    loader_val = DataLoader(dataset=loader_val, batch_size=256,shuffle=False)\n",
    "    \n",
    "    # We try to aggregate the several batches together \n",
    "    # so that we could have a big batchsize to fill in GPU.\n",
    "    # real_batch size = aggregated_batches * batch_size\n",
    "    aggregated_batches = 1\n",
    "    \n",
    "    for e in range(epochs):\n",
    "\n",
    "        train_map1 = AverageMeter()\n",
    "        train_map3 = AverageMeter()\n",
    "        \n",
    "        #Learning rate decay\n",
    "        adjust_learning_rate(optimizer, e, args)\n",
    "        \n",
    "        # We split the whole train dataset into 100 segments.\n",
    "        for i in range(20):\n",
    "            t1 = time.time()\n",
    "            total_loss = 0\n",
    "            train_dataset = QD.QDloadStrokeData(no=i,val = False,transforms = trans)          \n",
    "            train_loader = DataLoader(dataset=train_dataset, batch_size=256,shuffle=False)\n",
    "            for t, (x,stroke, y) in enumerate(train_loader):\n",
    "                model.train()  \n",
    "                x = x.to(device=device, dtype=dtype)  \n",
    "                y = y.to(device=device, dtype=torch.long)\n",
    "\n",
    "                #add the center feature returned from resnet \n",
    "                scores,cf_pred = model(x)\n",
    "                \n",
    "                #Caculate entropy loss\n",
    "                entropy_loss = F.cross_entropy(scores, y)\n",
    "                \n",
    "                #Caculate the center loss \n",
    "                center_loss = F.mse_loss(cf_pred,cf_class[y])\n",
    "                \n",
    "                loss = entropy_loss + alpha * center_loss\n",
    "                \n",
    "                total_loss += loss\n",
    "        \n",
    "                                  \n",
    "                if t % aggregated_batches == 0:                    \n",
    "                    avg_loss = total_loss / aggregated_batches\n",
    "                    \n",
    "                    #Calculate train accuracy\n",
    "                    y_pred = scores.data.cpu().numpy()\n",
    "                    y_val = y.reshape(-1,1)\n",
    "\n",
    "                    mAP = 100 * mean_ap_3(y_val,y_pred,1)\n",
    "                    mAP3 = 100 * mean_ap_3(y_val,y_pred,3)\n",
    "\n",
    "                    #train_map1.update(mAP,x.size(0))\n",
    "                    #train_map3.update(mAP3,x.size(0))\n",
    "                    \n",
    "                    optimizer.zero_grad()\n",
    "                    avg_loss.backward()\n",
    "                    optimizer.step()\n",
    "                    total_loss = 0\n",
    "\n",
    "                    t2 = time.time()\n",
    "\n",
    "                    if t % (print_every) == 0:\n",
    "                        print('Epoch %d,Iteration %d,loss = %.4f,time %.4f,train accuracy(%.2f,%.2f)' % \n",
    "                              (e,t, avg_loss.item(),t2-t1,mAP,mAP3))\n",
    "                        check_accuracy(loader_val, model)\n",
    "                        t1 = time.time()\n",
    "                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model = RN.resnet50(num_classes=40)\n",
    "optimizer = optim.Adam(cnn_model.parameters(),lr = args['learning_rate'])\n",
    "QDtrain = {\"mAP\":0,\"mAP3\":0,\"file\":\"\",\"prefix\":\"resnet50\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train(cnn_model,optimizer, epochs=5,args=args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. batch size = 64. count =  340 * 10240.\n",
    "   Iteration 29400, loss = 0.5610\n",
    "   Got 64 correct (80.22,85.62)\n",
    "2. batch size =128 count = 340 *10240 * 2\n",
    "    Iteration 37800, loss = 0.9535\n",
    "    Got 128 correct (77.65,83.64)\n",
    "3. batch size =128 count = 340 *10240 * 2 \n",
    "    train on 28 * 28 drawing transfered from stroke\n",
    "    Iteration 45900, loss = 0.9149\n",
    "    Got correct (57.55,65.98)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following codes comes from cs231N.\n",
    "from average_precision import mapk\n",
    "def mean_ap_torch(y_val,y_pred_score,k):\n",
    "    y_pred = [torch.sort(c,descending=True)[::-1][1][:k] for c in y_pred_score]\n",
    "    return mapk(y_val,y_pred,k)\n",
    "\n",
    "def mean_ap_3(y_val,y_pred_score,k):\n",
    "    y_pred = [np.argsort(c)[::-1][:k] for c in y_pred_score]\n",
    "    return mapk(y_val,y_pred,k)\n",
    "\n",
    "def check_accuracy(loader, model):\n",
    "    \n",
    "    model.eval()  # set model to evaluation mode\n",
    "    \n",
    "    meanAP = []\n",
    "    meanAP3 = []\n",
    "    with torch.no_grad():\n",
    "        for i ,(_,x, y) in enumerate(loader):\n",
    "            x = x.to(device=device, dtype=dtype)  # move to device, e.g. GPU\n",
    "            y = y.to(device=device, dtype=torch.long)\n",
    "            y_pred,_ = model(x,None)\n",
    "            y_val = y.reshape(-1,1)\n",
    "            y_pred = y_pred.data.cpu().numpy()\n",
    "            \n",
    "            mAP = 100 * mean_ap_3(y_val,y_pred,1)\n",
    "            mAP3 = 100 * mean_ap_3(y_val,y_pred,3)\n",
    "            meanAP.append(mAP)\n",
    "            meanAP3.append(mAP3)\n",
    "            if i > 100:\n",
    "                break\n",
    "        \n",
    "        m1 = np.mean(meanAP)\n",
    "        m3 = np.mean(meanAP3)\n",
    "        \n",
    "\n",
    "        if (m3 > QDtrain[\"mAP3\"] + 1) and (m3 > 20):\n",
    "            if os.path.exists(QDtrain[\"file\"]):\n",
    "                os.remove(QDtrain[\"file\"])\n",
    "            QDtrain[\"file\"] = str(\"model\" + QDtrain[\"prefix\"] + str(m3))\n",
    "            torch.save(model.state_dict(),QDtrain[\"file\"])\n",
    "            QDtrain[\"mAP3\"] = m3\n",
    "            QDtrain[\"mAP\"] = m1\n",
    "        print('Got correct (%.2f,%.2f)' % (m1,m3 ))\n",
    "        \n",
    "        \n",
    "def train(model, optimizer, epochs,args):\n",
    "    \"\"\"\n",
    "    Train a model on quickdrawing.\n",
    "    \n",
    "    Inputs:\n",
    "    - model: A PyTorch Module giving the model to train.\n",
    "    - optimizer: An Optimizer object we will use to train the model\n",
    "    - epochs: A Python integer giving the number of epochs to train for\n",
    "    - args: argumetns for learning rate\n",
    "    \n",
    "    Returns: Nothing, but prints model accuracies during training.\n",
    "    \"\"\"\n",
    "\n",
    "    model = model.to(device=device)  # move the model parameters to CPU/GPU\n",
    "    loader_val = QD.QDloadStrokeData(val = True)\n",
    "    loader_val = DataLoader(dataset=loader_val, batch_size=512,shuffle=False)\n",
    "    \n",
    "    # We try to aggregate the several batches together \n",
    "    # so that we could have a big batchsize to fill in GPU.\n",
    "    # real_batch size = aggregated_batches * batch_size\n",
    "    aggregated_batches = 1\n",
    "    \n",
    "    for e in range(epochs):\n",
    "\n",
    "        train_map1 = AverageMeter()\n",
    "        train_map3 = AverageMeter()\n",
    "        \n",
    "        #Learning rate decay\n",
    "        adjust_learning_rate(optimizer, e, args)\n",
    "        \n",
    "        # We split the whole train dataset into 100 segments.\n",
    "        for i in range(20):\n",
    "            t1 = time.time()\n",
    "            total_loss = 0\n",
    "            train_dataset = QD.QDloadStrokeData(no=i,val = False,transforms = trans)          \n",
    "            train_loader = DataLoader(dataset=train_dataset, batch_size=512,shuffle=False)\n",
    "            for t, (_, x, y) in enumerate(train_loader):\n",
    "                model.train()  \n",
    "                x = x.to(device=device, dtype=dtype)  \n",
    "                y = y.to(device=device, dtype=torch.long)\n",
    "                \n",
    "                #add the center feature returned from resnet \n",
    "                scores,_ = model(x,None)\n",
    "                #Caculate entropy loss\n",
    "                entropy_loss = F.cross_entropy(scores, y)\n",
    "                \n",
    "                total_loss += entropy_loss\n",
    "                #Calculate train accuracy\n",
    "                y_pred = scores.data.cpu().numpy()\n",
    "                y_val = y.reshape(-1,1)\n",
    "                \n",
    "                mAP = 100 * mean_ap_3(y_val,y_pred,1)\n",
    "                mAP3 = 100 * mean_ap_3(y_val,y_pred,3)\n",
    "             \n",
    "                if t % aggregated_batches == 0:                    \n",
    "                    avg_loss = total_loss / aggregated_batches\n",
    "\n",
    "                    optimizer.zero_grad()\n",
    "                    avg_loss.backward()\n",
    "                    optimizer.step()\n",
    "                    total_loss = 0\n",
    "\n",
    "                    t2 = time.time()\n",
    "\n",
    "                    if t % (print_every) == 0:\n",
    "                        print('Epoch %d,Iteration %d,loss = %.4f,time %.4f,train accuracy(%.2f,%.2f)' % \n",
    "                              (e,t, avg_loss.item(),t2-t1,mAP,mAP3))\n",
    "                        check_accuracy(loader_val, model)\n",
    "                        t1 = time.time()\n",
    "                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "QDtrain = {\"mAP\":0,\"mAP3\":0,\"file\":\"\",\"prefix\":\"rnn\"}\n",
    "rnn_model = SketchRNN(3, 256, 40,dropout=0.1)\n",
    "optimizer = optim.Adam(rnn_model.parameters(),lr = args['learning_rate'])\n",
    "train(rnn_model,optimizer, epochs=5,args=args)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Sketch Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Super Sketch Network links a RNN and CNN together with an attention layer in the last layer.\n",
    "class SSN(nn.Module):\n",
    "    \n",
    "    def __init__(self, cnn_model_name,rnn_model_name, d_frozen = True,num_classes=40):\n",
    "        super(SSN, self).__init__()\n",
    "        \n",
    "        self.cnn = RN.resnet50(num_classes=num_classes)\n",
    "        self.rnn = SketchRNN(3, 256, num_classes,dropout=0.1)\n",
    "        \n",
    "        self.attention = nn.Parameter(torch.FloatTensor(num_classes, 1))\n",
    "        torch.nn.init.xavier_normal_(self.attention)\n",
    "        \n",
    "        if os.path.exists(cnn_model_name):\n",
    "            self.cnn.load_state_dict(torch.load(cnn_model_name, map_location=lambda storage, loc: storage))\n",
    "\n",
    "        if os.path.exists(rnn_model_name):\n",
    "            self.rnn.load_state_dict(torch.load(rnn_model_name, map_location=lambda storage, loc: storage))\n",
    "            \n",
    "        if d_frozen:\n",
    "            for param in self.cnn.parameters():\n",
    "                param.requires_grad = False\n",
    "            for param in self.rnn.parameters():\n",
    "                param.requires_grad = False\n",
    "                \n",
    "        \n",
    "    def forward(self, images,strokes):\n",
    "        cnn_output,cnn_f = self.cnn(images)\n",
    "        rnn_output,rnn_f = self.rnn(strokes,None)\n",
    "        \n",
    "        #Attention Layer linking RNN and CNN together.\n",
    "        output = torch.stack([cnn_output,rnn_output],dim = 1)\n",
    "        \n",
    "        #Get the center feature\n",
    "        ssn_feat = torch.cat((cnn_f,rnn_f),dim = 1)\n",
    "        att_score = torch.matmul(output, self.attention).squeeze()\n",
    "        att_score = F.softmax(att_score,dim = 1).view(output.size(0), output.size(1), 1)\n",
    "        score = output * att_score\n",
    "\n",
    "        score = torch.sum(score, dim=1)\n",
    "        \n",
    "        return score,ssn_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following codes comes from cs231N.\n",
    "from average_precision import mapk\n",
    "def mean_ap_torch(y_val,y_pred_score,k):\n",
    "    y_pred = [torch.sort(c,descending=True)[::-1][1][:k] for c in y_pred_score]\n",
    "    return mapk(y_val,y_pred,k)\n",
    "\n",
    "def mean_ap_3(y_val,y_pred_score,k):\n",
    "    y_pred = [np.argsort(c)[::-1][:k] for c in y_pred_score]\n",
    "    return mapk(y_val,y_pred,k)\n",
    "\n",
    "def check_accuracy(loader, model):\n",
    "    \n",
    "    model.eval()  # set model to evaluation mode\n",
    "    \n",
    "    meanAP = []\n",
    "    meanAP3 = []\n",
    "    with torch.no_grad():\n",
    "        for i ,(img,stroke, y) in enumerate(loader):\n",
    "            img = img.to(device=device, dtype=dtype)\n",
    "            stroke = stroke.to(device=device, dtype=dtype)\n",
    "            y = y.to(device=device, dtype=torch.long)\n",
    "            y_pred,_ = model(img,stroke)\n",
    "            y_val = y.reshape(-1,1)\n",
    "            y_pred = y_pred.data.cpu().numpy()\n",
    "            \n",
    "            mAP = 100 * mean_ap_3(y_val,y_pred,1)\n",
    "            mAP3 = 100 * mean_ap_3(y_val,y_pred,3)\n",
    "            meanAP.append(mAP)\n",
    "            meanAP3.append(mAP3)\n",
    "            if i > 100:\n",
    "                break\n",
    "        \n",
    "        m1 = np.mean(meanAP)\n",
    "        m3 = np.mean(meanAP3)\n",
    "        \n",
    "\n",
    "        if (m3 > QDtrain[\"mAP3\"] + 0.1) and (m3 > 80):\n",
    "            if os.path.exists(QDtrain[\"file\"]):\n",
    "                os.remove(QDtrain[\"file\"])\n",
    "            QDtrain[\"file\"] = str(\"model\" + QDtrain[\"prefix\"] + str(m3))\n",
    "            torch.save(model.state_dict(),QDtrain[\"file\"])\n",
    "            QDtrain[\"mAP3\"] = m3\n",
    "            QDtrain[\"mAP\"] = m1\n",
    "        print('Got correct (%.2f,%.2f)' % (m1,m3 ))\n",
    "        \n",
    "        \n",
    "def train(model, optimizer, epochs,args):\n",
    "    \"\"\"\n",
    "    Train a model on quickdrawing.\n",
    "    \n",
    "    Inputs:\n",
    "    - model: A PyTorch Module giving the model to train.\n",
    "    - optimizer: An Optimizer object we will use to train the model\n",
    "    - epochs: A Python integer giving the number of epochs to train for\n",
    "    - args: argumetns for learning rate\n",
    "    \n",
    "    Returns: Nothing, but prints model accuracies during training.\n",
    "    \"\"\"\n",
    "\n",
    "    model = model.to(device=device)  # move the model parameters to CPU/GPU\n",
    "    loader_val = QD.QDloadStrokeData(val = True)\n",
    "    loader_val = DataLoader(dataset=loader_val, batch_size=256,shuffle=False)\n",
    "    \n",
    "    # We try to aggregate the several batches together \n",
    "    # so that we could have a big batchsize to fill in GPU.\n",
    "    # real_batch size = aggregated_batches * batch_size\n",
    "    aggregated_batches = 1\n",
    "    \n",
    "    for e in range(epochs):\n",
    "\n",
    "        train_map1 = AverageMeter()\n",
    "        train_map3 = AverageMeter()\n",
    "        \n",
    "        #Learning rate decay\n",
    "        adjust_learning_rate(optimizer, e, args)\n",
    "        \n",
    "        # We split the whole train dataset into 100 segments.\n",
    "        for i in range(20):\n",
    "            t1 = time.time()\n",
    "            total_loss = 0\n",
    "            train_dataset = QD.QDloadStrokeData(no=i,val = False,transforms = trans)          \n",
    "            train_loader = DataLoader(dataset=train_dataset, batch_size=256,shuffle=False)\n",
    "            for t, (img, stroke, y) in enumerate(train_loader):\n",
    "                model.train()  \n",
    "                img = img.to(device=device, dtype=dtype)  \n",
    "                stroke = stroke.to(device=device, dtype=dtype)\n",
    "                y = y.to(device=device, dtype=torch.long)\n",
    "                \n",
    "                #add the center feature returned from resnet \n",
    "                scores,cf_pred = model(img,stroke)\n",
    "                \n",
    "                #Caculate entropy loss\n",
    "                entropy_loss = F.cross_entropy(scores, y)\n",
    "\n",
    "                #Caculate the center loss \n",
    "                center_loss = F.mse_loss(cf_pred,cf_class[y])\n",
    "                \n",
    "                loss = entropy_loss + alpha * center_loss\n",
    "                \n",
    "                total_loss += loss\n",
    "                                        \n",
    "                if t % aggregated_batches == 0:                    \n",
    "                    avg_loss = total_loss / aggregated_batches  \n",
    "                    \n",
    "                    optimizer.zero_grad()\n",
    "                    avg_loss.backward()\n",
    "                    optimizer.step()\n",
    "                    total_loss = 0\n",
    "\n",
    "                    t2 = time.time()\n",
    "\n",
    "                    if t % (print_every) == 0:\n",
    "                        \n",
    "                        #Calculate train accuracy\n",
    "                        y_pred = scores.data.cpu().numpy()\n",
    "                        y_val = y.reshape(-1,1)\n",
    "\n",
    "                        mAP = 100 * mean_ap_3(y_val,y_pred,1)\n",
    "                        mAP3 = 100 * mean_ap_3(y_val,y_pred,3)\n",
    "                    \n",
    "                        print('Epoch %d,Iteration %d,loss = %.4f,time %.4f,train accuracy(%.2f,%.2f)' % \n",
    "                              (e,t, avg_loss.item(),t2-t1,mAP,mAP3))\n",
    "                        check_accuracy(loader_val, model)\n",
    "                        t1 = time.time()\n",
    "                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "QDtrain = {\"mAP\":0,\"mAP3\":0,\"file\":\"\",\"prefix\":\"SSN\"}\n",
    "args[\"learning_rate\"] = 5e-4\n",
    "ssn_model = SSN(\"modelresnet5091.17106\",\"rnn_model_88.34\")\n",
    "optimizer = optim.Adam(ssn_model.parameters(),lr = args['learning_rate'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(ssn_model,optimizer, epochs=5,args=args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run test samples\n",
    "* Run the whole test daset to get the accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_test(test_data, model,args):\n",
    "    model.eval()  \n",
    "    with torch.no_grad():\n",
    "        meanAP = []\n",
    "        meanAP3 = []\n",
    "        center_feature = []\n",
    "        y_eval_list = []\n",
    "        \n",
    "        for i ,(img,stroke,y) in enumerate(test_data):\n",
    "            img = img.to(device=device, dtype=dtype)\n",
    "            stroke = stroke.to(device=device, dtype=dtype)\n",
    "            y = y.to(device=device, dtype=torch.long)\n",
    "            \n",
    "            if args['model']=='ssn':\n",
    "                y_pred,feature_pred = model(img,stroke)\n",
    "                feature_pred = feature_pred.data.cpu().numpy()\n",
    "                center_feature.extend(feature_pred)\n",
    "                \n",
    "            if args['model']=='cnn':\n",
    "                y_pred,feature_pred = model(img)\n",
    "                feature_pred = feature_pred.data.cpu().numpy()\n",
    "                center_feature.extend(feature_pred)\n",
    "                #print(len(center_feature),center_feature[0].shape)\n",
    "                \n",
    "            if args['model']=='rnn':\n",
    "                y_pred,_ = model(stroke,None)\n",
    "                \n",
    "            y_val = y.reshape(-1,1)\n",
    "            y_pred = y_pred.data.cpu().numpy()\n",
    "            \n",
    "            y_pred_label = np.argmax(y_pred,axis=1)\n",
    "            y_label = y.data.cpu().numpy()\n",
    "\n",
    "            y_eval_list.append((y_label,y_pred_label))\n",
    "            \n",
    "            mAP = 100 * mean_ap_3(y_val,y_pred,1)\n",
    "            mAP3 = 100 * mean_ap_3(y_val,y_pred,3)\n",
    "            meanAP.append(mAP)\n",
    "            meanAP3.append(mAP3)\n",
    "    \n",
    "        m1 = np.mean(meanAP)\n",
    "        m3 = np.mean(meanAP3)\n",
    "        \n",
    "        return (m1,m3,center_feature,y_eval_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Run the test dataset to evaluate the performance of SSN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args['model'] = 'rnn'\n",
    "model = rnn_model\n",
    "model = model.to(device=device)\n",
    "checkpoint = torch.load(\"rnn_model_88.34\")\n",
    "model.load_state_dict(checkpoint)\n",
    "\n",
    "def run_testdataset(args,model,file_name = \"test_dataset.csv\"):\n",
    "    batch_size = 512\n",
    "    data_file = os.path.join(\"./test\",file_name)\n",
    "    test_data = QD.QDloadStrokeData(data_file = data_file)\n",
    "    test_loader = DataLoader(dataset=test_data, batch_size=batch_size, num_workers=2, shuffle=False)\n",
    "\n",
    "    m1,m3,feature_list,y_eval_list = evaluate_test(test_loader,model,args)\n",
    "    print(\" Got the correct %.4f %.4f classification\" % (m1,m3))\n",
    "    return y_eval_list,test_data\n",
    "\n",
    "y_eval_list,test_data = run_testdataset(args,model) \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "matrix = np.zeros((40,40))\n",
    "for i,item in enumerate(y_eval_list):\n",
    "    for j in range(512):\n",
    "        matrix[i][y_eval_list[i][1][j]] +=1\n",
    "        if y_eval_list[i][1][j] != i:\n",
    "            print(i,j,y_eval_list[i][1][j])\n",
    "        \n",
    "df_cm = pd.DataFrame(matrix, index = [name for name in QD.qd_names],\n",
    "                  columns = [name for name in QD.qd_names],dtype = np.int16)\n",
    "plt.figure(figsize = (15,7))\n",
    "sn.heatmap(df_cm, annot=True, fmt=\"d\")\n",
    "\n",
    "\n",
    "#Just rename some category for the display.\n",
    "cat_names =['cup','garden hose', 'marker', 'truck', 'oven', 'cooler', 'birthday cake',\n",
    "'camouflage', 'pool', 'dog', 'bear','bird', 'Great Wall','van',\n",
    "'tiger', 'bench', 'pickup truck','coffee cup', 'telephone', 'mug','matches',\n",
    "'animal migration', 'lantern', 'skyscraper','keyboard','foot','monkey','sleeping bag',\n",
    "'brain', 'peanut', 'belt', 'tent','cookie', 'cake','hot dog',\n",
    "'violin', 'cello', 'donut', 'hourglass', 'bee']\n",
    "\n",
    "#We choose 10 categories to form a confusion matrix\n",
    "cat = [0,3,6,10,12,16,17,19,26,33]\n",
    "small = np.zeros((10,10))\n",
    "\n",
    "l = 0\n",
    "for i in range(40):\n",
    "    if i in cat:\n",
    "        k = 0\n",
    "        for j in range(40):\n",
    "            if j in cat:\n",
    "                small[l][k] = matrix[i][j]\n",
    "                #print(i,cat_names[j],matrix[i][j])\n",
    "                k += 1\n",
    "        l += 1\n",
    "\n",
    "df_cm = pd.DataFrame(small, index = [cat_names[n] for n in cat],\n",
    "                  columns = [cat_names[n] for n in cat],dtype = np.int16)\n",
    "plt.figure(figsize = (4,2))\n",
    "sn.heatmap(df_cm, annot=True, fmt=\"d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig,axs = plt.subplots(nrows=1, ncols=3, figsize=(4,2))\n",
    "img,_,_ = test_data[0*512 + 14]\n",
    "axs[0].set_title(\"cup:coffe\")\n",
    "axs[0].imshow(img.reshape(96,96))\n",
    "\n",
    "img,_,_ = test_data[17*512 + 100]\n",
    "axs[1].set_title(\"coffee:mug\")\n",
    "axs[1].imshow(img.reshape(96,96))\n",
    "\n",
    "img,_,_ = test_data[0*512 + 16]\n",
    "axs[2].set_title(\"mug:cup\")\n",
    "axs[2].imshow(img.reshape(96,96))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,axs = plt.subplots(nrows=1, ncols=2, figsize=(3,2))\n",
    "img,_,_ = test_data[10*512 + 18]\n",
    "axs[0].set_title(\"bear:monkey\")\n",
    "axs[0].imshow(img.reshape(96,96))\n",
    "\n",
    "img,_,_ = test_data[26*512 + 100]\n",
    "axs[1].set_title(\"monkey:bear\")\n",
    "axs[1].imshow(img.reshape(96,96))\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,axs = plt.subplots(nrows=1, ncols=2, figsize=(3,2))\n",
    "img,_,_ = test_data[6*512 + 100]\n",
    "axs[0].set_title(\"birthday:cake\")\n",
    "axs[0].imshow(img.reshape(96,96))\n",
    "\n",
    "img,_,_ = test_data[33*512 + 2]\n",
    "axs[1].set_title(\"cake:birthday\")\n",
    "axs[1].imshow(img.reshape(96,96))\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,axs = plt.subplots(nrows=1, ncols=2, figsize=(4,2))\n",
    "img,_,_ = test_data[10*512 + 52]\n",
    "axs[0].set_title(\"RNN\")\n",
    "axs[0].imshow(img.reshape(96,96))\n",
    "\n",
    "img,_,_ = test_data[10*512 + 137]\n",
    "axs[1].set_title(\"RNN\")\n",
    "axs[1].imshow(img.reshape(96,96))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args['model'] = 'cnn'\n",
    "model = cnn_model\n",
    "\n",
    "model = model.to(device=device)\n",
    "checkpoint = torch.load(\"ssn_model_loss_center_89.50\")\n",
    "model.load_state_dict(checkpoint)\n",
    "\n",
    "class_name = QD.qd_names\n",
    "\n",
    "class_accuracy = []\n",
    "center_feature = []\n",
    "y_list = []\n",
    "\n",
    "val_accuracy_map1 = AverageMeter()\n",
    "val_accuracy_map3 = AverageMeter()\n",
    "\n",
    "for i,name in enumerate(tqdm(class_name)):\n",
    "    t1 = time.time()\n",
    "    batch_size = 128\n",
    "    data_file = os.path.join(\"./train\",name+\".csv\")\n",
    "    test_data = QD.QDloadStrokeData(data_file = data_file)\n",
    "    test_loader = DataLoader(dataset=test_data, batch_size=batch_size, num_workers=2, shuffle=False)\n",
    "\n",
    "    m1,m3,feature_list,y_eval_list = evaluate_test(test_loader,model,args)\n",
    "    \n",
    "    if args['model'] != 'rnn':\n",
    "        feature_list = np.array(feature_list)\n",
    "        print(feature_list.shape)\n",
    "\n",
    "        #feature_list is N * 2048\n",
    "        center_feature.append(np.mean(feature_list,axis = 0))\n",
    "        \n",
    "    class_accuracy.append((name,str(m1),str(m3)))\n",
    "    y_list.extend(y_eval_list)\n",
    "    \n",
    "    val_accuracy_map1.update(m1,len(y_eval_list))\n",
    "    val_accuracy_map3.update(m3,len(y_eval_list))\n",
    "    \n",
    "    print(name,str(m1),str(m3))\n",
    "    t2 = time.time()\n",
    "    print(\"Time:\",t2-t1)\n",
    "    \n",
    "with open('class_accuracy.csv',\"w+\") as fp:\n",
    "    writer = csv.writer(fp, delimiter=',')\n",
    "    writer.writerow([\"class\", \"meanAP1\", \"meanAP3\"])  # write header\n",
    "    writer.writerows(class_accuracy)\n",
    "\n",
    "print(\"The average accuracy %.4f %.4f\" % (val_accuracy_map1.avg,val_accuracy_map3.avg))\n",
    "np.save(\"y_test_list\",y_list)\n",
    "\n",
    "if args['model'] != 'rnn':\n",
    "    np.save(\"center_feature_\" + args['model'],center_feature)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(ssn_model.state_dict(),\"ssn_model_91.52_freeze\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
